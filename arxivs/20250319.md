## Updated on 2025.03.19

## Autonomous_Driving_Planning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-17**|**InsightDrive: Insight Scene Representation for End-to-End Autonomous Driving**|Ruiqi Song et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13047v1-b31b1b.svg)](http://arxiv.org/abs/2503.13047v1)|null|
|**2025-03-17**|**OptiPMB: Enhancing 3D Multi-Object Tracking with Optimized Poisson Multi-Bernoulli Filtering**|Guanhua Ding et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12968v1-b31b1b.svg)](http://arxiv.org/abs/2503.12968v1)|null|
|**2025-03-15**|**DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving**|Tao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12170v1-b31b1b.svg)](http://arxiv.org/abs/2503.12170v1)|null|
|**2025-03-15**|**Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12030v1-b31b1b.svg)](http://arxiv.org/abs/2503.12030v1)|null|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving**|Tin Stribor Sohn et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11400v1-b31b1b.svg)](http://arxiv.org/abs/2503.11400v1)|null|
|**2025-03-13**|**DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10621v1-b31b1b.svg)](http://arxiv.org/abs/2503.10621v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ayesha-ishaq/drivelmm-o1)**|
|**2025-03-13**|**Finetuning Generative Trajectory Model with Reinforcement Learning from Human Feedback**|Derun Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10434v1-b31b1b.svg)](http://arxiv.org/abs/2503.10434v1)|null|
|**2025-03-17**|**Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latent Space**|Jian Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09215v2-b31b1b.svg)](http://arxiv.org/abs/2503.09215v2)|null|

## Autonomous_Driving_Prediction

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-17**|**AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction**|Thomas Monninger et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13430v1-b31b1b.svg)](http://arxiv.org/abs/2503.13430v1)|null|
|**2025-03-17**|**Clustering is back: Reaching state-of-the-art LiDAR instance segmentation without training**|Corentin Sautier et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13203v1-b31b1b.svg)](http://arxiv.org/abs/2503.13203v1)|null|
|**2025-03-17**|**InsightDrive: Insight Scene Representation for End-to-End Autonomous Driving**|Ruiqi Song et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13047v1-b31b1b.svg)](http://arxiv.org/abs/2503.13047v1)|null|
|**2025-03-16**|**Understanding Driver Cognition and Decision-Making Behaviors in High-Risk Scenarios: A Drift Diffusion Perspective**|Heye Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12637v1-b31b1b.svg)](http://arxiv.org/abs/2503.12637v1)|null|
|**2025-03-16**|**Point Cloud Based Scene Segmentation: A Survey**|Dan Halperin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12595v1-b31b1b.svg)](http://arxiv.org/abs/2503.12595v1)|null|
|**2025-03-16**|**L2COcc: Lightweight Camera-Centric Semantic Scene Completion via Distillation of LiDAR Model**|Ruoyu Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12369v1-b31b1b.svg)](http://arxiv.org/abs/2503.12369v1)|null|
|**2025-03-15**|**DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving**|Tao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12170v1-b31b1b.svg)](http://arxiv.org/abs/2503.12170v1)|null|
|**2025-03-15**|**Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12030v1-b31b1b.svg)](http://arxiv.org/abs/2503.12030v1)|null|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**Learning-Based MPC for Efficient Control of Autonomous Vehicles**|Samuel Mallick et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11359v1-b31b1b.svg)](http://arxiv.org/abs/2503.11359v1)|null|

## Autonomous_Driving_Decision

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|
|**2025-03-18**|**A Reference Architecture for Autonomous Networks: An Agent-Based Approach**|Joseph Sifakis et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12871v2-b31b1b.svg)](http://arxiv.org/abs/2503.12871v2)|null|
|**2025-03-16**|**Understanding Driver Cognition and Decision-Making Behaviors in High-Risk Scenarios: A Drift Diffusion Perspective**|Heye Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12637v1-b31b1b.svg)](http://arxiv.org/abs/2503.12637v1)|null|
|**2025-03-15**|**Generative Modeling of Adversarial Lane-Change Scenario**|Chuancheng Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12055v1-b31b1b.svg)](http://arxiv.org/abs/2503.12055v1)|null|
|**2025-03-15**|**Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12030v1-b31b1b.svg)](http://arxiv.org/abs/2503.12030v1)|null|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving**|Tin Stribor Sohn et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11400v1-b31b1b.svg)](http://arxiv.org/abs/2503.11400v1)|null|
|**2025-03-14**|**Active Learning from Scene Embeddings for End-to-End Autonomous Driving**|Wenhao Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11062v1-b31b1b.svg)](http://arxiv.org/abs/2503.11062v1)|null|
|**2025-03-13**|**DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10621v1-b31b1b.svg)](http://arxiv.org/abs/2503.10621v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ayesha-ishaq/drivelmm-o1)**|
|**2025-03-12**|**Edge AI-Powered Real-Time Decision-Making for Autonomous Vehicles in Adverse Weather Conditions**|Milad Rahmati et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09638v1-b31b1b.svg)](http://arxiv.org/abs/2503.09638v1)|null|

## Autonomous_Driving_E2E

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-17**|**Clustering is back: Reaching state-of-the-art LiDAR instance segmentation without training**|Corentin Sautier et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13203v1-b31b1b.svg)](http://arxiv.org/abs/2503.13203v1)|null|
|**2025-03-17**|**InsightDrive: Insight Scene Representation for End-to-End Autonomous Driving**|Ruiqi Song et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13047v1-b31b1b.svg)](http://arxiv.org/abs/2503.13047v1)|null|
|**2025-03-17**|**Hydra-MDP++: Advancing End-to-End Driving via Expert-Guided Hydra-Distillation**|Kailin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12820v1-b31b1b.svg)](http://arxiv.org/abs/2503.12820v1)|null|
|**2025-03-15**|**Bench2FreeAD: A Benchmark for Vision-based End-to-end Navigation in Unstructured Robotic Environments**|Yuhang Peng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12180v1-b31b1b.svg)](http://arxiv.org/abs/2503.12180v1)|null|
|**2025-03-15**|**DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving**|Tao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12170v1-b31b1b.svg)](http://arxiv.org/abs/2503.12170v1)|null|
|**2025-03-15**|**Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12030v1-b31b1b.svg)](http://arxiv.org/abs/2503.12030v1)|null|
|**2025-03-14**|**Industrial-Grade Sensor Simulation via Gaussian Splatting: A Modular Framework for Scalable Editing and Full-Stack Validation**|Xianming Zeng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11731v1-b31b1b.svg)](http://arxiv.org/abs/2503.11731v1)|null|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**BEVDiffLoc: End-to-End LiDAR Global Localization in BEV View based on Diffusion Model**|Ziyue Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11372v1-b31b1b.svg)](http://arxiv.org/abs/2503.11372v1)|null|
|**2025-03-14**|**DynRsl-VLM: Enhancing Autonomous Driving Perception with Dynamic Resolution Vision-Language Models**|Xirui Zhou et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11265v1-b31b1b.svg)](http://arxiv.org/abs/2503.11265v1)|null|

## Autonomous_Driving_LLM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|
|**2025-03-12**|**SimLingo: Vision-Only Closed-Loop Autonomous Driving with Language-Action Alignment**|Katrin Renz et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09594v1-b31b1b.svg)](http://arxiv.org/abs/2503.09594v1)|null|

## Autonomous_Driving_RL

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|
|**2025-03-14**|**Controllable Latent Diffusion for Traffic Simulation**|Yizhuo Xiao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11771v1-b31b1b.svg)](http://arxiv.org/abs/2503.11771v1)|null|
|**2025-03-13**|**Finetuning Generative Trajectory Model with Reinforcement Learning from Human Feedback**|Derun Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10434v1-b31b1b.svg)](http://arxiv.org/abs/2503.10434v1)|null|
|**2025-03-12**|**Edge AI-Powered Real-Time Decision-Making for Autonomous Vehicles in Adverse Weather Conditions**|Milad Rahmati et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09638v1-b31b1b.svg)](http://arxiv.org/abs/2503.09638v1)|null|

## World_Model

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|
|**2025-03-17**|**SAM2 for Image and Video Segmentation: A Comprehensive Survey**|Zhang Jiaxing et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12781v1-b31b1b.svg)](http://arxiv.org/abs/2503.12781v1)|null|
|**2025-03-16**|**Logic-RAG: Augmenting Large Multimodal Models with Visual-Spatial Knowledge for Road Scene Understanding**|Imran Kabir et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12663v1-b31b1b.svg)](http://arxiv.org/abs/2503.12663v1)|null|
|**2025-03-16**|**Understanding Driver Cognition and Decision-Making Behaviors in High-Risk Scenarios: A Drift Diffusion Perspective**|Heye Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12637v1-b31b1b.svg)](http://arxiv.org/abs/2503.12637v1)|null|
|**2025-03-16**|**Towards Suturing World Models: Learning Predictive Models for Robotic Surgical Tasks**|Mehmet Kerem Turkcan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12531v1-b31b1b.svg)](http://arxiv.org/abs/2503.12531v1)|null|
|**2025-03-15**|**Bench2FreeAD: A Benchmark for Vision-based End-to-end Navigation in Unstructured Robotic Environments**|Yuhang Peng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12180v1-b31b1b.svg)](http://arxiv.org/abs/2503.12180v1)|null|
|**2025-03-15**|**TACO: Taming Diffusion for in-the-wild Video Amodal Completion**|Ruijie Lu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12049v1-b31b1b.svg)](http://arxiv.org/abs/2503.12049v1)|null|
|**2025-03-14**|**Controllable Latent Diffusion for Traffic Simulation**|Yizhuo Xiao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11771v1-b31b1b.svg)](http://arxiv.org/abs/2503.11771v1)|null|
|**2025-03-14**|**A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving**|Tin Stribor Sohn et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11400v1-b31b1b.svg)](http://arxiv.org/abs/2503.11400v1)|null|
|**2025-03-14**|**DriveGEN: Generalized and Robust 3D Detection in Driving via Controllable Text-to-Image Diffusion Generation**|Hongbin Lin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11122v1-b31b1b.svg)](http://arxiv.org/abs/2503.11122v1)|null|

