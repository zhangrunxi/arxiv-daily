## Updated on 2025.05.29

## Autonomous_Driving_Planning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-28**|**GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control**|Anthony Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22421v1-b31b1b.svg)](http://arxiv.org/abs/2505.22421v1)|null|
|**2025-05-27**|**CogAD: Cognitive-Hierarchy Guided End-to-End Autonomous Driving**|Zhennan Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21581v1-b31b1b.svg)](http://arxiv.org/abs/2505.21581v1)|null|
|**2025-05-27**|**Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**|Muzhi Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21457v1-b31b1b.svg)](http://arxiv.org/abs/2505.21457v1)|null|
|**2025-05-27**|**RefAV: Towards Planning-Centric Scenario Mining**|Cainan Davidson et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20981v1-b31b1b.svg)](http://arxiv.org/abs/2505.20981v1)|null|
|**2025-05-27**|**Generalized Coordination of Partially Cooperative Urban Traffic**|Max Bastian Mertens et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20879v1-b31b1b.svg)](http://arxiv.org/abs/2505.20879v1)|null|
|**2025-05-27**|**DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving**|Muxi Diao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20665v1-b31b1b.svg)](http://arxiv.org/abs/2505.20665v1)|null|
|**2025-05-26**|**ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving**|Xueyi Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20024v1-b31b1b.svg)](http://arxiv.org/abs/2505.20024v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/liuxueyi/reasonplan)**|
|**2025-05-25**|**Echo Planning for Autonomous Driving: From Current Observations to Future Trajectories and Back**|Jintao Sun et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.18945v1-b31b1b.svg)](http://arxiv.org/abs/2505.18945v1)|null|
|**2025-05-23**|**RQR3D: Reparametrizing the regression targets for BEV-based 3D object detection**|Ozsel Kilinc et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17732v1-b31b1b.svg)](http://arxiv.org/abs/2505.17732v1)|null|
|**2025-05-23**|**SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**|Jiawei Zhou et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17727v1-b31b1b.svg)](http://arxiv.org/abs/2505.17727v1)|null|

## Autonomous_Driving_Prediction

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-28**|**A Human-Centric Approach to Explainable AI for Personalized Education**|Vinitra Swamy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22541v1-b31b1b.svg)](http://arxiv.org/abs/2505.22541v1)|null|
|**2025-05-28**|**The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector**|Aixuan Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22499v1-b31b1b.svg)](http://arxiv.org/abs/2505.22499v1)|null|
|**2025-05-28**|**SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels**|Qiucheng Yu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22461v1-b31b1b.svg)](http://arxiv.org/abs/2505.22461v1)|null|
|**2025-05-28**|**LiDARDustX: A LiDAR Dataset for Dusty Unstructured Road Environments**|Chenfeng Wei et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21914v1-b31b1b.svg)](http://arxiv.org/abs/2505.21914v1)|null|
|**2025-05-27**|**Towards Human-Like Trajectory Prediction for Autonomous Driving: A Behavior-Centric Approach**|Haicheng Liao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21565v1-b31b1b.svg)](http://arxiv.org/abs/2505.21565v1)|null|
|**2025-05-27**|**Robust Video-Based Pothole Detection and Area Estimation for Intelligent Vehicles with Depth Map and Kalman Smoothing**|Dehao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21049v1-b31b1b.svg)](http://arxiv.org/abs/2505.21049v1)|null|
|**2025-05-27**|**RF4D:Neural Radar Fields for Novel View Synthesis in Outdoor Dynamic Scenes**|Jiarui Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20967v1-b31b1b.svg)](http://arxiv.org/abs/2505.20967v1)|null|
|**2025-05-27**|**DSOcc: Leveraging Depth Awareness and Semantic Aid to Boost Camera-Based 3D Semantic Occupancy Prediction**|Naiyu Fang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20951v1-b31b1b.svg)](http://arxiv.org/abs/2505.20951v1)|null|
|**2025-05-27**|**DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving**|Muxi Diao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20665v1-b31b1b.svg)](http://arxiv.org/abs/2505.20665v1)|null|
|**2025-05-27**|**OccLE: Label-Efficient 3D Semantic Occupancy Prediction**|Naiyu Fang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20617v1-b31b1b.svg)](http://arxiv.org/abs/2505.20617v1)|null|

## Autonomous_Driving_Decision

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-28**|**A Human-Centric Approach to Explainable AI for Personalized Education**|Vinitra Swamy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22541v1-b31b1b.svg)](http://arxiv.org/abs/2505.22541v1)|null|
|**2025-05-28**|**An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints**|Jiahui Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21841v1-b31b1b.svg)](http://arxiv.org/abs/2505.21841v1)|null|
|**2025-05-27**|**Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**|Muzhi Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21457v1-b31b1b.svg)](http://arxiv.org/abs/2505.21457v1)|null|
|**2025-05-27**|**DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving**|Muxi Diao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20665v1-b31b1b.svg)](http://arxiv.org/abs/2505.20665v1)|null|
|**2025-05-26**|**ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving**|Xueyi Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20024v1-b31b1b.svg)](http://arxiv.org/abs/2505.20024v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/liuxueyi/reasonplan)**|
|**2025-05-26**|**Uncertainty-Aware Safety-Critical Decision and Control for Autonomous Vehicles at Unsignalized Intersections**|Ran Yu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19939v1-b31b1b.svg)](http://arxiv.org/abs/2505.19939v1)|null|
|**2025-05-27**|**DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving**|Anqing Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19381v2-b31b1b.svg)](http://arxiv.org/abs/2505.19381v2)|null|
|**2025-05-24**|**ProphetDWM: A Driving World Model for Rolling Out Future Actions and Videos**|Xiaodong Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.18650v1-b31b1b.svg)](http://arxiv.org/abs/2505.18650v1)|null|
|**2025-05-23**|**Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play**|Jiaxun Cui et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.18334v1-b31b1b.svg)](http://arxiv.org/abs/2505.18334v1)|null|
|**2025-05-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Xuesong Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16805v1-b31b1b.svg)](http://arxiv.org/abs/2505.16805v1)|null|

## Autonomous_Driving_E2E

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-28**|**Learnable Burst-Encodable Time-of-Flight Imaging for High-Fidelity Long-Distance Depth Sensing**|Manchao Bao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22025v1-b31b1b.svg)](http://arxiv.org/abs/2505.22025v1)|null|
|**2025-05-27**|**CogAD: Cognitive-Hierarchy Guided End-to-End Autonomous Driving**|Zhennan Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21581v1-b31b1b.svg)](http://arxiv.org/abs/2505.21581v1)|null|
|**2025-05-27**|**A first look at ROS~2 applications written in asynchronous Rust**|Martin Škoudlil et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21323v1-b31b1b.svg)](http://arxiv.org/abs/2505.21323v1)|null|
|**2025-05-27**|**RF4D:Neural Radar Fields for Novel View Synthesis in Outdoor Dynamic Scenes**|Jiarui Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20967v1-b31b1b.svg)](http://arxiv.org/abs/2505.20967v1)|null|
|**2025-05-27**|**A New View to Mission Profiles**|Horst Lewitschnig et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20792v1-b31b1b.svg)](http://arxiv.org/abs/2505.20792v1)|null|
|**2025-05-27**|**DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving**|Muxi Diao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20665v1-b31b1b.svg)](http://arxiv.org/abs/2505.20665v1)|null|
|**2025-05-26**|**ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving**|Xueyi Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20024v1-b31b1b.svg)](http://arxiv.org/abs/2505.20024v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/liuxueyi/reasonplan)**|
|**2025-05-26**|**DiffE2E: Rethinking End-to-End Driving with a Hybrid Action Diffusion and Supervised Policy**|Rui Zhao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19516v1-b31b1b.svg)](http://arxiv.org/abs/2505.19516v1)|null|
|**2025-05-27**|**DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving**|Anqing Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19381v2-b31b1b.svg)](http://arxiv.org/abs/2505.19381v2)|null|
|**2025-05-25**|**DriveX: Omni Scene Modeling for Learning Generalizable World Knowledge in Autonomous Driving**|Chen Shi et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19239v1-b31b1b.svg)](http://arxiv.org/abs/2505.19239v1)|null|

## Autonomous_Driving_LLM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-28**|**A Human-Centric Approach to Explainable AI for Personalized Education**|Vinitra Swamy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22541v1-b31b1b.svg)](http://arxiv.org/abs/2505.22541v1)|null|
|**2025-05-28**|**From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving**|Xinyu Xia et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22067v1-b31b1b.svg)](http://arxiv.org/abs/2505.22067v1)|null|
|**2025-05-27**|**Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge**|Yue Fang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20658v1-b31b1b.svg)](http://arxiv.org/abs/2505.20658v1)|null|
|**2025-05-26**|**Learning to Reason without External Rewards**|Xuandong Zhao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19590v1-b31b1b.svg)](http://arxiv.org/abs/2505.19590v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/sunblaze-ucb/intuitor)**|
|**2025-05-25**|**Sensorimotor features of self-awareness in multimodal large language models**|Iñaki Dellibarda Varela et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19237v1-b31b1b.svg)](http://arxiv.org/abs/2505.19237v1)|null|
|**2025-05-23**|**Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play**|Jiaxun Cui et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.18334v1-b31b1b.svg)](http://arxiv.org/abs/2505.18334v1)|null|
|**2025-05-23**|**Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour**|Bálint Gyevnár et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17801v1-b31b1b.svg)](http://arxiv.org/abs/2505.17801v1)|null|
|**2025-05-22**|**LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios**|Huaiyuan Yao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17209v1-b31b1b.svg)](http://arxiv.org/abs/2505.17209v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/hyan-yao/lilodriver)**|

## Autonomous_Driving_RL

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-28**|**An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints**|Jiahui Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21841v1-b31b1b.svg)](http://arxiv.org/abs/2505.21841v1)|null|
|**2025-05-27**|**Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**|Muzhi Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21457v1-b31b1b.svg)](http://arxiv.org/abs/2505.21457v1)|null|
|**2025-05-26**|**Uncertainty-Aware Safety-Critical Decision and Control for Autonomous Vehicles at Unsignalized Intersections**|Ran Yu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19939v1-b31b1b.svg)](http://arxiv.org/abs/2505.19939v1)|null|
|**2025-05-26**|**Learning to Reason without External Rewards**|Xuandong Zhao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19590v1-b31b1b.svg)](http://arxiv.org/abs/2505.19590v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/sunblaze-ucb/intuitor)**|
|**2025-05-23**|**Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour**|Bálint Gyevnár et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17801v1-b31b1b.svg)](http://arxiv.org/abs/2505.17801v1)|null|
|**2025-05-27**|**Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**|Xiaolong Tang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17659v2-b31b1b.svg)](http://arxiv.org/abs/2505.17659v2)|null|

## World_Model

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-28**|**A Human-Centric Approach to Explainable AI for Personalized Education**|Vinitra Swamy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22541v1-b31b1b.svg)](http://arxiv.org/abs/2505.22541v1)|null|
|**2025-05-28**|**The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector**|Aixuan Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22499v1-b31b1b.svg)](http://arxiv.org/abs/2505.22499v1)|null|
|**2025-05-28**|**GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control**|Anthony Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22421v1-b31b1b.svg)](http://arxiv.org/abs/2505.22421v1)|null|
|**2025-05-27**|**Do you see what I see? An Ambiguous Optical Illusion Dataset exposing limitations of Explainable AI**|Carina Newen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21589v1-b31b1b.svg)](http://arxiv.org/abs/2505.21589v1)|null|
|**2025-05-27**|**CogAD: Cognitive-Hierarchy Guided End-to-End Autonomous Driving**|Zhennan Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21581v1-b31b1b.svg)](http://arxiv.org/abs/2505.21581v1)|null|
|**2025-05-27**|**Towards Human-Like Trajectory Prediction for Autonomous Driving: A Behavior-Centric Approach**|Haicheng Liao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21565v1-b31b1b.svg)](http://arxiv.org/abs/2505.21565v1)|null|
|**2025-05-27**|**Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**|Muzhi Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21457v1-b31b1b.svg)](http://arxiv.org/abs/2505.21457v1)|null|
|**2025-05-27**|**Robust Video-Based Pothole Detection and Area Estimation for Intelligent Vehicles with Depth Map and Kalman Smoothing**|Dehao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21049v1-b31b1b.svg)](http://arxiv.org/abs/2505.21049v1)|null|
|**2025-05-27**|**DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving**|Anqing Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19381v2-b31b1b.svg)](http://arxiv.org/abs/2505.19381v2)|null|
|**2025-05-25**|**DriveX: Omni Scene Modeling for Learning Generalizable World Knowledge in Autonomous Driving**|Chen Shi et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.19239v1-b31b1b.svg)](http://arxiv.org/abs/2505.19239v1)|null|

