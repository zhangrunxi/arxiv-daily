## Updated on 2025.06.03

## Autonomous_Driving_Planning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-30**|**SAH-Drive: A Scenario-Aware Hybrid Planner for Closed-Loop Vehicle Trajectory Generation**|Yuqi Fan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24390v1-b31b1b.svg)](http://arxiv.org/abs/2505.24390v1)|null|
|**2025-05-30**|**DTR: Delaunay Triangulation-based Racing for Scaled Autonomous Racing**|Luca Tognoni et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24320v1-b31b1b.svg)](http://arxiv.org/abs/2505.24320v1)|null|
|**2025-05-30**|**S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation**|Yichen Xie et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24139v1-b31b1b.svg)](http://arxiv.org/abs/2505.24139v1)|null|
|**2025-05-29**|**Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models**|Haohan Chi et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23757v1-b31b1b.svg)](http://arxiv.org/abs/2505.23757v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ahydchh/impromptu-vla)**|
|**2025-05-29**|**Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving**|Yunshen Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23115v1-b31b1b.svg)](http://arxiv.org/abs/2505.23115v1)|null|
|**2025-05-29**|**GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control**|Anthony Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22421v2-b31b1b.svg)](http://arxiv.org/abs/2505.22421v2)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/antonioo-c/geodrive)**|
|**2025-06-01**|**CogAD: Cognitive-Hierarchy Guided End-to-End Autonomous Driving**|Zhennan Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21581v2-b31b1b.svg)](http://arxiv.org/abs/2505.21581v2)|null|
|**2025-05-27**|**Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**|Muzhi Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21457v1-b31b1b.svg)](http://arxiv.org/abs/2505.21457v1)|null|
|**2025-05-27**|**RefAV: Towards Planning-Centric Scenario Mining**|Cainan Davidson et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20981v1-b31b1b.svg)](http://arxiv.org/abs/2505.20981v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/cainand/refav)**|
|**2025-05-27**|**Generalized Coordination of Partially Cooperative Urban Traffic**|Max Bastian Mertens et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20879v1-b31b1b.svg)](http://arxiv.org/abs/2505.20879v1)|null|

## Autonomous_Driving_Prediction

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-30**|**S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation**|Yichen Xie et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24139v1-b31b1b.svg)](http://arxiv.org/abs/2505.24139v1)|null|
|**2025-05-29**|**Towards Understanding The Calibration Benefits of Sharpness-Aware Minimization**|Chengli Tan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23866v1-b31b1b.svg)](http://arxiv.org/abs/2505.23866v1)|null|
|**2025-05-29**|**Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models**|Haohan Chi et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23757v1-b31b1b.svg)](http://arxiv.org/abs/2505.23757v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ahydchh/impromptu-vla)**|
|**2025-05-29**|**Autoregressive Meta-Actions for Unified Controllable Trajectory Generation**|Jianbo Zhao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23612v1-b31b1b.svg)](http://arxiv.org/abs/2505.23612v1)|null|
|**2025-05-29**|**Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving**|Yunshen Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23115v1-b31b1b.svg)](http://arxiv.org/abs/2505.23115v1)|null|
|**2025-05-28**|**A Human-Centric Approach to Explainable AI for Personalized Education**|Vinitra Swamy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22541v1-b31b1b.svg)](http://arxiv.org/abs/2505.22541v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/epfl-ml4ed/interpretcc)**|
|**2025-05-29**|**The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector**|Aixuan Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22499v2-b31b1b.svg)](http://arxiv.org/abs/2505.22499v2)|null|
|**2025-05-29**|**SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels**|Qiucheng Yu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22461v2-b31b1b.svg)](http://arxiv.org/abs/2505.22461v2)|null|
|**2025-05-28**|**LiDARDustX: A LiDAR Dataset for Dusty Unstructured Road Environments**|Chenfeng Wei et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21914v1-b31b1b.svg)](http://arxiv.org/abs/2505.21914v1)|null|
|**2025-05-27**|**Robust Video-Based Pothole Detection and Area Estimation for Intelligent Vehicles with Depth Map and Kalman Smoothing**|Dehao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21049v1-b31b1b.svg)](http://arxiv.org/abs/2505.21049v1)|null|

## Autonomous_Driving_Decision

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-30**|**Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks**|Tajamul Ashraf et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24876v1-b31b1b.svg)](http://arxiv.org/abs/2505.24876v1)|null|
|**2025-05-30**|**SAH-Drive: A Scenario-Aware Hybrid Planner for Closed-Loop Vehicle Trajectory Generation**|Yuqi Fan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24390v1-b31b1b.svg)](http://arxiv.org/abs/2505.24390v1)|null|
|**2025-05-30**|**ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving**|Yongming Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24317v1-b31b1b.svg)](http://arxiv.org/abs/2505.24317v1)|null|
|**2025-05-29**|**Autoregressive Meta-Actions for Unified Controllable Trajectory Generation**|Jianbo Zhao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23612v1-b31b1b.svg)](http://arxiv.org/abs/2505.23612v1)|null|
|**2025-05-29**|**Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception**|Guangyuan Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23275v1-b31b1b.svg)](http://arxiv.org/abs/2505.23275v1)|null|
|**2025-05-28**|**A Human-Centric Approach to Explainable AI for Personalized Education**|Vinitra Swamy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22541v1-b31b1b.svg)](http://arxiv.org/abs/2505.22541v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/epfl-ml4ed/interpretcc)**|
|**2025-05-28**|**An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints**|Jiahui Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21841v1-b31b1b.svg)](http://arxiv.org/abs/2505.21841v1)|null|
|**2025-05-27**|**Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**|Muzhi Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21457v1-b31b1b.svg)](http://arxiv.org/abs/2505.21457v1)|null|
|**2025-05-27**|**DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving**|Muxi Diao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20665v1-b31b1b.svg)](http://arxiv.org/abs/2505.20665v1)|null|

## Autonomous_Driving_E2E

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-30**|**DTR: Delaunay Triangulation-based Racing for Scaled Autonomous Racing**|Luca Tognoni et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24320v1-b31b1b.svg)](http://arxiv.org/abs/2505.24320v1)|null|
|**2025-05-30**|**S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation**|Yichen Xie et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24139v1-b31b1b.svg)](http://arxiv.org/abs/2505.24139v1)|null|
|**2025-05-29**|**HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring**|Bin Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23129v1-b31b1b.svg)](http://arxiv.org/abs/2505.23129v1)|null|
|**2025-05-28**|**Learnable Burst-Encodable Time-of-Flight Imaging for High-Fidelity Long-Distance Depth Sensing**|Manchao Bao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22025v1-b31b1b.svg)](http://arxiv.org/abs/2505.22025v1)|null|
|**2025-06-01**|**CogAD: Cognitive-Hierarchy Guided End-to-End Autonomous Driving**|Zhennan Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21581v2-b31b1b.svg)](http://arxiv.org/abs/2505.21581v2)|null|
|**2025-06-02**|**A first look at ROS 2 applications written in asynchronous Rust**|Martin Å koudlil et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21323v2-b31b1b.svg)](http://arxiv.org/abs/2505.21323v2)|null|
|**2025-05-31**|**RF4D:Neural Radar Fields for Novel View Synthesis in Outdoor Dynamic Scenes**|Jiarui Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20967v2-b31b1b.svg)](http://arxiv.org/abs/2505.20967v2)|null|
|**2025-05-27**|**A New View to Mission Profiles**|Horst Lewitschnig et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20792v1-b31b1b.svg)](http://arxiv.org/abs/2505.20792v1)|null|
|**2025-05-27**|**DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving**|Muxi Diao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20665v1-b31b1b.svg)](http://arxiv.org/abs/2505.20665v1)|null|

## Autonomous_Driving_LLM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-29**|**Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception**|Guangyuan Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23275v1-b31b1b.svg)](http://arxiv.org/abs/2505.23275v1)|null|
|**2025-05-29**|**Context-Aware Semantic Communication for the Wireless Networks**|Guangyuan Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23249v1-b31b1b.svg)](http://arxiv.org/abs/2505.23249v1)|null|
|**2025-05-28**|**A Human-Centric Approach to Explainable AI for Personalized Education**|Vinitra Swamy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22541v1-b31b1b.svg)](http://arxiv.org/abs/2505.22541v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/epfl-ml4ed/interpretcc)**|
|**2025-05-28**|**From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving**|Xinyu Xia et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22067v1-b31b1b.svg)](http://arxiv.org/abs/2505.22067v1)|null|
|**2025-05-27**|**Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge**|Yue Fang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.20658v1-b31b1b.svg)](http://arxiv.org/abs/2505.20658v1)|null|

## Autonomous_Driving_RL

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-30**|**ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving**|Yongming Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24317v1-b31b1b.svg)](http://arxiv.org/abs/2505.24317v1)|null|
|**2025-05-29**|**Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception**|Guangyuan Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23275v1-b31b1b.svg)](http://arxiv.org/abs/2505.23275v1)|null|
|**2025-05-29**|**Context-Aware Semantic Communication for the Wireless Networks**|Guangyuan Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23249v1-b31b1b.svg)](http://arxiv.org/abs/2505.23249v1)|null|
|**2025-05-28**|**An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints**|Jiahui Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21841v1-b31b1b.svg)](http://arxiv.org/abs/2505.21841v1)|null|
|**2025-05-27**|**Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**|Muzhi Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21457v1-b31b1b.svg)](http://arxiv.org/abs/2505.21457v1)|null|

## World_Model

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-30**|**Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks**|Tajamul Ashraf et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24876v1-b31b1b.svg)](http://arxiv.org/abs/2505.24876v1)|null|
|**2025-05-30**|**Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation**|Roger Ferrod et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.24361v1-b31b1b.svg)](http://arxiv.org/abs/2505.24361v1)|null|
|**2025-05-29**|**Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving**|Yunshen Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.23115v1-b31b1b.svg)](http://arxiv.org/abs/2505.23115v1)|null|
|**2025-05-28**|**A Human-Centric Approach to Explainable AI for Personalized Education**|Vinitra Swamy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22541v1-b31b1b.svg)](http://arxiv.org/abs/2505.22541v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/epfl-ml4ed/interpretcc)**|
|**2025-05-29**|**The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector**|Aixuan Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22499v2-b31b1b.svg)](http://arxiv.org/abs/2505.22499v2)|null|
|**2025-05-29**|**GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control**|Anthony Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.22421v2-b31b1b.svg)](http://arxiv.org/abs/2505.22421v2)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/antonioo-c/geodrive)**|
|**2025-05-27**|**Do you see what I see? An Ambiguous Optical Illusion Dataset exposing limitations of Explainable AI**|Carina Newen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21589v1-b31b1b.svg)](http://arxiv.org/abs/2505.21589v1)|null|
|**2025-06-01**|**CogAD: Cognitive-Hierarchy Guided End-to-End Autonomous Driving**|Zhennan Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21581v2-b31b1b.svg)](http://arxiv.org/abs/2505.21581v2)|null|
|**2025-05-27**|**Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**|Muzhi Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21457v1-b31b1b.svg)](http://arxiv.org/abs/2505.21457v1)|null|
|**2025-05-27**|**Robust Video-Based Pothole Detection and Area Estimation for Intelligent Vehicles with Depth Map and Kalman Smoothing**|Dehao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.21049v1-b31b1b.svg)](http://arxiv.org/abs/2505.21049v1)|null|

