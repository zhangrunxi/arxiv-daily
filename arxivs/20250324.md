## Updated on 2025.03.24

## Autonomous_Driving_Planning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-21**|**OpenCity3D: What do Vision-Language Models know about Urban Environments?**|Valentin Bieri et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16776v1-b31b1b.svg)](http://arxiv.org/abs/2503.16776v1)|null|
|**2025-03-20**|**Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models**|Chengkai Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16734v1-b31b1b.svg)](http://arxiv.org/abs/2503.16734v1)|null|
|**2025-03-19**|**A Vehicle-Infrastructure Multi-layer Cooperative Decision-making Framework**|Yiming Cui et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16552v1-b31b1b.svg)](http://arxiv.org/abs/2503.16552v1)|null|
|**2025-03-20**|**AutoDrive-QA- Automated Generation of Multiple-Choice Questions for Autonomous Driving Datasets Using Large Vision-Language Models**|Boshra Khalili et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15778v1-b31b1b.svg)](http://arxiv.org/abs/2503.15778v1)|null|
|**2025-03-18**|**Generating Causal Explanations of Vehicular Agent Behavioural Interactions with Learnt Reward Profiles**|Rhys Howard et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14557v1-b31b1b.svg)](http://arxiv.org/abs/2503.14557v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/cognitive-robots/gce_vbai_lrp_paper_resources)**|
|**2025-03-18**|**Tracking Meets Large Multimodal Models for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14498v1-b31b1b.svg)](http://arxiv.org/abs/2503.14498v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/mbzuai-oryx/trackingmeetslmm)**|
|**2025-03-18**|**Bridging Past and Future: End-to-End Autonomous Driving with Historical Prediction and Planning**|Bozhou Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14182v1-b31b1b.svg)](http://arxiv.org/abs/2503.14182v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/fudan-zvg/bridgead)**|
|**2025-03-18**|**A Systematic Digital Engineering Approach to Verification & Validation of Autonomous Ground Vehicles in Off-Road Environments**|Tanmay Vilas Samak et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13787v1-b31b1b.svg)](http://arxiv.org/abs/2503.13787v1)|null|

## Autonomous_Driving_Prediction

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-21**|**Hi-ALPS -- An Experimental Robustness Quantification of Six LiDAR-based Object Detection Systems for Autonomous Driving**|Alexandra Arzberger et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.17168v1-b31b1b.svg)](http://arxiv.org/abs/2503.17168v1)|null|
|**2025-03-21**|**OpenCity3D: What do Vision-Language Models know about Urban Environments?**|Valentin Bieri et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16776v1-b31b1b.svg)](http://arxiv.org/abs/2503.16776v1)|null|
|**2025-03-20**|**MiLA: Multi-view Intensive-fidelity Long-term Video Generation World Model for Autonomous Driving**|Haiguang Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15875v1-b31b1b.svg)](http://arxiv.org/abs/2503.15875v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/xiaomi-mlab/mila.github.io)**|
|**2025-03-20**|**AutoDrive-QA- Automated Generation of Multiple-Choice Questions for Autonomous Driving Datasets Using Large Vision-Language Models**|Boshra Khalili et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15778v1-b31b1b.svg)](http://arxiv.org/abs/2503.15778v1)|null|
|**2025-03-19**|**GASP: Unifying Geometric and Semantic Self-Supervised Pre-training for Autonomous Driving**|William Ljungbergh et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15672v1-b31b1b.svg)](http://arxiv.org/abs/2503.15672v1)|null|
|**2025-03-19**|**Generating Multimodal Driving Scenes via Next-Scene Prediction**|Yanhao Wu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14945v1-b31b1b.svg)](http://arxiv.org/abs/2503.14945v1)|null|
|**2025-03-19**|**SemanticFlow: A Self-Supervised Framework for Joint Scene Flow Prediction and Instance Segmentation in Dynamic Environments**|Yinqi Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14837v1-b31b1b.svg)](http://arxiv.org/abs/2503.14837v1)|null|
|**2025-03-18**|**RAT: Boosting Misclassification Detection Ability without Extra Data**|Ge Yan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14783v1-b31b1b.svg)](http://arxiv.org/abs/2503.14783v1)|null|
|**2025-03-18**|**Tracking Meets Large Multimodal Models for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14498v1-b31b1b.svg)](http://arxiv.org/abs/2503.14498v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/mbzuai-oryx/trackingmeetslmm)**|
|**2025-03-18**|**Bridging Past and Future: End-to-End Autonomous Driving with Historical Prediction and Planning**|Bozhou Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14182v1-b31b1b.svg)](http://arxiv.org/abs/2503.14182v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/fudan-zvg/bridgead)**|

## Autonomous_Driving_Decision

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-21**|**How to Promote Autonomous Driving with Evolving Technology: Business Strategy and Pricing Decision**|Mingliang Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.17174v1-b31b1b.svg)](http://arxiv.org/abs/2503.17174v1)|null|
|**2025-03-21**|**Hi-ALPS -- An Experimental Robustness Quantification of Six LiDAR-based Object Detection Systems for Autonomous Driving**|Alexandra Arzberger et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.17168v1-b31b1b.svg)](http://arxiv.org/abs/2503.17168v1)|null|
|**2025-03-20**|**Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models**|Chengkai Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16734v1-b31b1b.svg)](http://arxiv.org/abs/2503.16734v1)|null|
|**2025-03-19**|**A Vehicle-Infrastructure Multi-layer Cooperative Decision-making Framework**|Yiming Cui et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16552v1-b31b1b.svg)](http://arxiv.org/abs/2503.16552v1)|null|
|**2025-03-19**|**An Investigation of Beam Density on LiDAR Object Detection Performance**|Christoph Griesbacher et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15087v1-b31b1b.svg)](http://arxiv.org/abs/2503.15087v1)|null|
|**2025-03-18**|**RAD: Retrieval-Augmented Decision-Making of Meta-Actions with Vision-Language Models in Autonomous Driving**|Yujin Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13861v1-b31b1b.svg)](http://arxiv.org/abs/2503.13861v1)|null|
|**2025-03-19**|**From Autonomous Agents to Integrated Systems, A New Paradigm: Orchestrated Distributed Intelligence**|Krti Tallam et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13754v2-b31b1b.svg)](http://arxiv.org/abs/2503.13754v2)|null|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|

## Autonomous_Driving_E2E

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-20**|**AutoDrive-QA- Automated Generation of Multiple-Choice Questions for Autonomous Driving Datasets Using Large Vision-Language Models**|Boshra Khalili et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15778v1-b31b1b.svg)](http://arxiv.org/abs/2503.15778v1)|null|
|**2025-03-19**|**V2X-DG: Domain Generalization for Vehicle-to-Everything Cooperative Perception**|Baolu Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15435v1-b31b1b.svg)](http://arxiv.org/abs/2503.15435v1)|null|
|**2025-03-19**|**USAM-Net: A U-Net-based Network for Improved Stereo Correspondence and Scene Depth Estimation using Features from a Pre-trained Image Segmentation network**|Joseph Emmanuel DL Dayo et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14950v1-b31b1b.svg)](http://arxiv.org/abs/2503.14950v1)|null|
|**2025-03-18**|**Bridging Past and Future: End-to-End Autonomous Driving with Historical Prediction and Planning**|Bozhou Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14182v1-b31b1b.svg)](http://arxiv.org/abs/2503.14182v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/fudan-zvg/bridgead)**|
|**2025-03-18**|**A Systematic Digital Engineering Approach to Verification & Validation of Autonomous Ground Vehicles in Off-Road Environments**|Tanmay Vilas Samak et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13787v1-b31b1b.svg)](http://arxiv.org/abs/2503.13787v1)|null|
|**2025-03-17**|**Clustering is back: Reaching state-of-the-art LiDAR instance segmentation without training**|Corentin Sautier et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13203v1-b31b1b.svg)](http://arxiv.org/abs/2503.13203v1)|null|

## Autonomous_Driving_LLM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-20**|**Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models**|Chengkai Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16734v1-b31b1b.svg)](http://arxiv.org/abs/2503.16734v1)|null|
|**2025-03-19**|**A Vehicle-Infrastructure Multi-layer Cooperative Decision-making Framework**|Yiming Cui et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16552v1-b31b1b.svg)](http://arxiv.org/abs/2503.16552v1)|null|
|**2025-03-20**|**BadToken: Token-level Backdoor Attacks to Multi-modal Large Language Models**|Zenghui Yuan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16023v1-b31b1b.svg)](http://arxiv.org/abs/2503.16023v1)|null|
|**2025-03-20**|**AutoDrive-QA- Automated Generation of Multiple-Choice Questions for Autonomous Driving Datasets Using Large Vision-Language Models**|Boshra Khalili et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15778v1-b31b1b.svg)](http://arxiv.org/abs/2503.15778v1)|null|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|

## Autonomous_Driving_RL

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-19**|**HAD-Gen: Human-like and Diverse Driving Behavior Modeling for Controllable Scenario Generation**|Cheng Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15049v1-b31b1b.svg)](http://arxiv.org/abs/2503.15049v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/robosafe-lab/sim4ad)**|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|

## World_Model

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-21**|**Salient Object Detection in Traffic Scene through the TSOD10K Dataset**|Yu Qiu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16910v1-b31b1b.svg)](http://arxiv.org/abs/2503.16910v1)|null|
|**2025-03-20**|**BadToken: Token-level Backdoor Attacks to Multi-modal Large Language Models**|Zenghui Yuan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.16023v1-b31b1b.svg)](http://arxiv.org/abs/2503.16023v1)|null|
|**2025-03-20**|**MiLA: Multi-view Intensive-fidelity Long-term Video Generation World Model for Autonomous Driving**|Haiguang Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15875v1-b31b1b.svg)](http://arxiv.org/abs/2503.15875v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/xiaomi-mlab/mila.github.io)**|
|**2025-03-19**|**An Investigation of Beam Density on LiDAR Object Detection Performance**|Christoph Griesbacher et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.15087v1-b31b1b.svg)](http://arxiv.org/abs/2503.15087v1)|null|
|**2025-03-18**|**SimWorld: A Unified Benchmark for Simulator-Conditioned Scene Generation via World Model**|Xinqing Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13952v1-b31b1b.svg)](http://arxiv.org/abs/2503.13952v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/li-zn-h/simworld)**|
|**2025-03-18**|**Robust3D-CIL: Robust Class-Incremental Learning for 3D Perception**|Jinge Ma et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13869v1-b31b1b.svg)](http://arxiv.org/abs/2503.13869v1)|null|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|

