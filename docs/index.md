---
layout: default
---

## Updated on 2025.05.26

## Autonomous_Driving_Planning

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-23**|**RQR3D: Reparametrizing the regression targets for BEV-based 3D object detection**|Ozsel Kilinc et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17732v1-b31b1b.svg)](http://arxiv.org/abs/2505.17732v1)|null|
|**2025-05-23**|**SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**|Jiawei Zhou et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17727v1-b31b1b.svg)](http://arxiv.org/abs/2505.17727v1)|null|
|**2025-05-23**|**FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving**|Shuang Zeng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17685v1-b31b1b.svg)](http://arxiv.org/abs/2505.17685v1)|null|
|**2025-05-23**|**Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**|Xiaolong Tang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17659v1-b31b1b.svg)](http://arxiv.org/abs/2505.17659v1)|null|
|**2025-05-22**|**LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios**|Huaiyuan Yao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17209v1-b31b1b.svg)](http://arxiv.org/abs/2505.17209v1)|null|
|**2025-05-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Xuesong Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16805v1-b31b1b.svg)](http://arxiv.org/abs/2505.16805v1)|null|
|**2025-05-22**|**CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving**|Huitong Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16524v1-b31b1b.svg)](http://arxiv.org/abs/2505.16524v1)|null|
|**2025-05-22**|**Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models**|Augusto Luis Ballardini et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16498v1-b31b1b.svg)](http://arxiv.org/abs/2505.16498v1)|null|
|**2025-05-22**|**Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**|Zhenjie Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16394v1-b31b1b.svg)](http://arxiv.org/abs/2505.16394v1)|null|
|**2025-05-22**|**VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving**|Yansong Qu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16377v1-b31b1b.svg)](http://arxiv.org/abs/2505.16377v1)|null|

## Autonomous_Driving_Prediction

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-23**|**Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour**|B치lint Gyevn치r et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17801v1-b31b1b.svg)](http://arxiv.org/abs/2505.17801v1)|null|
|**2025-05-23**|**FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving**|Shuang Zeng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17685v1-b31b1b.svg)](http://arxiv.org/abs/2505.17685v1)|null|
|**2025-05-23**|**Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**|Xiaolong Tang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17659v1-b31b1b.svg)](http://arxiv.org/abs/2505.17659v1)|null|
|**2025-05-22**|**Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation**|Moru Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16985v1-b31b1b.svg)](http://arxiv.org/abs/2505.16985v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/mona4399/featuremixing)**|
|**2025-05-22**|**NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification**|NovelSeek Team et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16938v1-b31b1b.svg)](http://arxiv.org/abs/2505.16938v1)|null|
|**2025-05-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Xuesong Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16805v1-b31b1b.svg)](http://arxiv.org/abs/2505.16805v1)|null|
|**2025-05-22**|**CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving**|Huitong Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16524v1-b31b1b.svg)](http://arxiv.org/abs/2505.16524v1)|null|
|**2025-05-21**|**VERDI: VLM-Embedded Reasoning for Autonomous Driving**|Bowen Feng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15925v1-b31b1b.svg)](http://arxiv.org/abs/2505.15925v1)|null|
|**2025-05-21**|**HAMF: A Hybrid Attention-Mamba Framework for Joint Scene Context Understanding and Future Motion Representation Learning**|Xiaodong Mei et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15703v1-b31b1b.svg)](http://arxiv.org/abs/2505.15703v1)|null|
|**2025-05-21**|**ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving**|Yunsheng Ma et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15158v1-b31b1b.svg)](http://arxiv.org/abs/2505.15158v1)|null|

## Autonomous_Driving_Decision

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Xuesong Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16805v1-b31b1b.svg)](http://arxiv.org/abs/2505.16805v1)|null|
|**2025-05-22**|**Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models**|Augusto Luis Ballardini et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16498v1-b31b1b.svg)](http://arxiv.org/abs/2505.16498v1)|null|
|**2025-05-21**|**VERDI: VLM-Embedded Reasoning for Autonomous Driving**|Bowen Feng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15925v1-b31b1b.svg)](http://arxiv.org/abs/2505.15925v1)|null|
|**2025-05-21**|**Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control**|Seongmin Park et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15304v1-b31b1b.svg)](http://arxiv.org/abs/2505.15304v1)|null|
|**2025-05-21**|**ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving**|Yunsheng Ma et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15158v1-b31b1b.svg)](http://arxiv.org/abs/2505.15158v1)|null|
|**2025-05-20**|**Looking for an out: Affordances, uncertainty and collision avoidance behavior of human drivers**|Leif Johnson et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.14842v1-b31b1b.svg)](http://arxiv.org/abs/2505.14842v1)|null|

## Autonomous_Driving_E2E

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-23**|**SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**|Jiawei Zhou et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17727v1-b31b1b.svg)](http://arxiv.org/abs/2505.17727v1)|null|
|**2025-05-22**|**NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification**|NovelSeek Team et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16938v1-b31b1b.svg)](http://arxiv.org/abs/2505.16938v1)|null|
|**2025-05-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Xuesong Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16805v1-b31b1b.svg)](http://arxiv.org/abs/2505.16805v1)|null|
|**2025-05-22**|**CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving**|Huitong Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16524v1-b31b1b.svg)](http://arxiv.org/abs/2505.16524v1)|null|
|**2025-05-22**|**Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**|Zhenjie Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16394v1-b31b1b.svg)](http://arxiv.org/abs/2505.16394v1)|null|
|**2025-05-22**|**DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving**|Zhenjie Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16278v1-b31b1b.svg)](http://arxiv.org/abs/2505.16278v1)|null|
|**2025-05-21**|**VERDI: VLM-Embedded Reasoning for Autonomous Driving**|Bowen Feng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15925v1-b31b1b.svg)](http://arxiv.org/abs/2505.15925v1)|null|
|**2025-05-23**|**Challenger: Affordable Adversarial Driving Video Generation**|Zhiyuan Xu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15880v2-b31b1b.svg)](http://arxiv.org/abs/2505.15880v2)|null|
|**2025-05-21**|**Learning-based Autonomous Oversteer Control and Collision Avoidance**|Seokjun Lee et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15275v1-b31b1b.svg)](http://arxiv.org/abs/2505.15275v1)|null|
|**2025-05-21**|**ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving**|Yunsheng Ma et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15158v1-b31b1b.svg)](http://arxiv.org/abs/2505.15158v1)|null|

## Autonomous_Driving_LLM

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-23**|**Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour**|B치lint Gyevn치r et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17801v1-b31b1b.svg)](http://arxiv.org/abs/2505.17801v1)|null|
|**2025-05-22**|**LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios**|Huaiyuan Yao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17209v1-b31b1b.svg)](http://arxiv.org/abs/2505.17209v1)|null|
|**2025-05-22**|**Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models**|Augusto Luis Ballardini et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16498v1-b31b1b.svg)](http://arxiv.org/abs/2505.16498v1)|null|
|**2025-05-22**|**DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving**|Zhenjie Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16278v1-b31b1b.svg)](http://arxiv.org/abs/2505.16278v1)|null|
|**2025-05-22**|**HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving**|Zhiwen Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15793v2-b31b1b.svg)](http://arxiv.org/abs/2505.15793v2)|null|
|**2025-05-21**|**LiveVLM: Efficient Online Video Understanding via Streaming-Oriented KV Cache and Retrieval**|Zhenyu Ning et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15269v1-b31b1b.svg)](http://arxiv.org/abs/2505.15269v1)|null|
|**2025-05-21**|**ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving**|Yunsheng Ma et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15158v1-b31b1b.svg)](http://arxiv.org/abs/2505.15158v1)|null|
|**2025-05-20**|**Programmatic Video Prediction Using Large Language Models**|Hao Tang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.14948v1-b31b1b.svg)](http://arxiv.org/abs/2505.14948v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/metro-smiles/ProgGen)**|

## Autonomous_Driving_RL

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-23**|**Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour**|B치lint Gyevn치r et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17801v1-b31b1b.svg)](http://arxiv.org/abs/2505.17801v1)|null|
|**2025-05-23**|**Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**|Xiaolong Tang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17659v1-b31b1b.svg)](http://arxiv.org/abs/2505.17659v1)|null|
|**2025-05-22**|**Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**|Zhenjie Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16394v1-b31b1b.svg)](http://arxiv.org/abs/2505.16394v1)|null|
|**2025-05-22**|**VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving**|Yansong Qu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16377v1-b31b1b.svg)](http://arxiv.org/abs/2505.16377v1)|null|
|**2025-05-22**|**HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving**|Zhiwen Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15793v2-b31b1b.svg)](http://arxiv.org/abs/2505.15793v2)|null|
|**2025-05-21**|**Learning-based Autonomous Oversteer Control and Collision Avoidance**|Seokjun Lee et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.15275v1-b31b1b.svg)](http://arxiv.org/abs/2505.15275v1)|null|

## World_Model

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-23**|**Clip4Retrofit: Enabling Real-Time Image Labeling on Edge Devices via Cross-Architecture CLIP Distillation**|Li Zhong et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.18039v1-b31b1b.svg)](http://arxiv.org/abs/2505.18039v1)|null|
|**2025-05-23**|**SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**|Jiawei Zhou et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17727v1-b31b1b.svg)](http://arxiv.org/abs/2505.17727v1)|null|
|**2025-05-23**|**SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data**|Dong-Hee Kim et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17695v1-b31b1b.svg)](http://arxiv.org/abs/2505.17695v1)|null|
|**2025-05-23**|**FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving**|Shuang Zeng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17685v1-b31b1b.svg)](http://arxiv.org/abs/2505.17685v1)|null|
|**2025-05-23**|**Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**|Xiaolong Tang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17659v1-b31b1b.svg)](http://arxiv.org/abs/2505.17659v1)|null|
|**2025-05-22**|**ConvoyNext: A Scalable Testbed Platform for Cooperative Autonomous Vehicle Systems**|Hossein Maghsoumi et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17275v1-b31b1b.svg)](http://arxiv.org/abs/2505.17275v1)|null|
|**2025-05-22**|**LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios**|Huaiyuan Yao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.17209v1-b31b1b.svg)](http://arxiv.org/abs/2505.17209v1)|null|
|**2025-05-22**|**Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation**|Moru Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16985v1-b31b1b.svg)](http://arxiv.org/abs/2505.16985v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/mona4399/featuremixing)**|
|**2025-05-22**|**Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models**|Augusto Luis Ballardini et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16498v1-b31b1b.svg)](http://arxiv.org/abs/2505.16498v1)|null|
|**2025-05-22**|**Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**|Zhenjie Yang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2505.16394v1-b31b1b.svg)](http://arxiv.org/abs/2505.16394v1)|null|

