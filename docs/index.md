---
layout: default
---

## Updated on 2025.03.20

## Autonomous_Driving_Planning

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-03-18**|**Tracking Meets Large Multimodal Models for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14498v1-b31b1b.svg)](http://arxiv.org/abs/2503.14498v1)|null|
|**2025-03-18**|**Bridging Past and Future: End-to-End Autonomous Driving with Historical Prediction and Planning**|Bozhou Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14182v1-b31b1b.svg)](http://arxiv.org/abs/2503.14182v1)|null|
|**2025-03-18**|**A Systematic Digital Engineering Approach to Verification & Validation of Autonomous Ground Vehicles in Off-Road Environments**|Tanmay Vilas Samak et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13787v1-b31b1b.svg)](http://arxiv.org/abs/2503.13787v1)|null|
|**2025-03-17**|**InsightDrive: Insight Scene Representation for End-to-End Autonomous Driving**|Ruiqi Song et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13047v1-b31b1b.svg)](http://arxiv.org/abs/2503.13047v1)|null|
|**2025-03-17**|**OptiPMB: Enhancing 3D Multi-Object Tracking with Optimized Poisson Multi-Bernoulli Filtering**|Guanhua Ding et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12968v1-b31b1b.svg)](http://arxiv.org/abs/2503.12968v1)|null|
|**2025-03-15**|**DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving**|Tao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12170v1-b31b1b.svg)](http://arxiv.org/abs/2503.12170v1)|null|
|**2025-03-15**|**Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12030v1-b31b1b.svg)](http://arxiv.org/abs/2503.12030v1)|null|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving**|Tin Stribor Sohn et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11400v1-b31b1b.svg)](http://arxiv.org/abs/2503.11400v1)|null|
|**2025-03-13**|**DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10621v1-b31b1b.svg)](http://arxiv.org/abs/2503.10621v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ayesha-ishaq/drivelmm-o1)**|

## Autonomous_Driving_Prediction

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-03-18**|**Tracking Meets Large Multimodal Models for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14498v1-b31b1b.svg)](http://arxiv.org/abs/2503.14498v1)|null|
|**2025-03-18**|**Bridging Past and Future: End-to-End Autonomous Driving with Historical Prediction and Planning**|Bozhou Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14182v1-b31b1b.svg)](http://arxiv.org/abs/2503.14182v1)|null|
|**2025-03-17**|**AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction**|Thomas Monninger et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13430v1-b31b1b.svg)](http://arxiv.org/abs/2503.13430v1)|null|
|**2025-03-17**|**Clustering is back: Reaching state-of-the-art LiDAR instance segmentation without training**|Corentin Sautier et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13203v1-b31b1b.svg)](http://arxiv.org/abs/2503.13203v1)|null|
|**2025-03-17**|**InsightDrive: Insight Scene Representation for End-to-End Autonomous Driving**|Ruiqi Song et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13047v1-b31b1b.svg)](http://arxiv.org/abs/2503.13047v1)|null|
|**2025-03-16**|**Understanding Driver Cognition and Decision-Making Behaviors in High-Risk Scenarios: A Drift Diffusion Perspective**|Heye Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12637v1-b31b1b.svg)](http://arxiv.org/abs/2503.12637v1)|null|
|**2025-03-16**|**Point Cloud Based Scene Segmentation: A Survey**|Dan Halperin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12595v1-b31b1b.svg)](http://arxiv.org/abs/2503.12595v1)|null|
|**2025-03-16**|**L2COcc: Lightweight Camera-Centric Semantic Scene Completion via Distillation of LiDAR Model**|Ruoyu Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12369v1-b31b1b.svg)](http://arxiv.org/abs/2503.12369v1)|null|
|**2025-03-15**|**DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving**|Tao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12170v1-b31b1b.svg)](http://arxiv.org/abs/2503.12170v1)|null|
|**2025-03-15**|**Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12030v1-b31b1b.svg)](http://arxiv.org/abs/2503.12030v1)|null|

## Autonomous_Driving_Decision

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-03-18**|**RAD: Retrieval-Augmented Decision-Making of Meta-Actions with Vision-Language Models in Autonomous Driving**|Yujin Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13861v1-b31b1b.svg)](http://arxiv.org/abs/2503.13861v1)|null|
|**2025-03-19**|**From Autonomous Agents to Integrated Systems, A New Paradigm: Orchestrated Distributed Intelligence**|Krti Tallam et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13754v2-b31b1b.svg)](http://arxiv.org/abs/2503.13754v2)|null|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|
|**2025-03-19**|**A Reference Architecture for Autonomous Networks: An Agent-Based Approach**|Joseph Sifakis et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12871v3-b31b1b.svg)](http://arxiv.org/abs/2503.12871v3)|null|
|**2025-03-16**|**Understanding Driver Cognition and Decision-Making Behaviors in High-Risk Scenarios: A Drift Diffusion Perspective**|Heye Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12637v1-b31b1b.svg)](http://arxiv.org/abs/2503.12637v1)|null|
|**2025-03-15**|**Generative Modeling of Adversarial Lane-Change Scenario**|Chuancheng Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12055v1-b31b1b.svg)](http://arxiv.org/abs/2503.12055v1)|null|
|**2025-03-15**|**Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12030v1-b31b1b.svg)](http://arxiv.org/abs/2503.12030v1)|null|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving**|Tin Stribor Sohn et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11400v1-b31b1b.svg)](http://arxiv.org/abs/2503.11400v1)|null|
|**2025-03-14**|**Active Learning from Scene Embeddings for End-to-End Autonomous Driving**|Wenhao Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11062v1-b31b1b.svg)](http://arxiv.org/abs/2503.11062v1)|null|

## Autonomous_Driving_E2E

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-03-18**|**Bridging Past and Future: End-to-End Autonomous Driving with Historical Prediction and Planning**|Bozhou Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.14182v1-b31b1b.svg)](http://arxiv.org/abs/2503.14182v1)|null|
|**2025-03-18**|**A Systematic Digital Engineering Approach to Verification & Validation of Autonomous Ground Vehicles in Off-Road Environments**|Tanmay Vilas Samak et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13787v1-b31b1b.svg)](http://arxiv.org/abs/2503.13787v1)|null|
|**2025-03-17**|**WMINet: A Wheel-Mounted Inertial Learning Approach For Mobile-Robot Positioning**|Gal Versano et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13568v1-b31b1b.svg)](http://arxiv.org/abs/2503.13568v1)|null|
|**2025-03-17**|**Clustering is back: Reaching state-of-the-art LiDAR instance segmentation without training**|Corentin Sautier et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13203v1-b31b1b.svg)](http://arxiv.org/abs/2503.13203v1)|null|
|**2025-03-17**|**InsightDrive: Insight Scene Representation for End-to-End Autonomous Driving**|Ruiqi Song et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13047v1-b31b1b.svg)](http://arxiv.org/abs/2503.13047v1)|null|
|**2025-03-17**|**Hydra-MDP++: Advancing End-to-End Driving via Expert-Guided Hydra-Distillation**|Kailin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12820v1-b31b1b.svg)](http://arxiv.org/abs/2503.12820v1)|null|
|**2025-03-15**|**Bench2FreeAD: A Benchmark for Vision-based End-to-end Navigation in Unstructured Robotic Environments**|Yuhang Peng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12180v1-b31b1b.svg)](http://arxiv.org/abs/2503.12180v1)|null|
|**2025-03-15**|**DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving**|Tao Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12170v1-b31b1b.svg)](http://arxiv.org/abs/2503.12170v1)|null|
|**2025-03-15**|**Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12030v1-b31b1b.svg)](http://arxiv.org/abs/2503.12030v1)|null|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|

## Autonomous_Driving_LLM

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|

## Autonomous_Driving_RL

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|
|**2025-03-19**|**Controllable Latent Diffusion for Traffic Simulation**|Yizhuo Xiao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11771v2-b31b1b.svg)](http://arxiv.org/abs/2503.11771v2)|null|
|**2025-03-13**|**Finetuning Generative Trajectory Model with Reinforcement Learning from Human Feedback**|Derun Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10434v1-b31b1b.svg)](http://arxiv.org/abs/2503.10434v1)|null|

## World_Model

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-03-18**|**SimWorld: A Unified Benchmark for Simulator-Conditioned Scene Generation via World Model**|Xinqing Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13952v1-b31b1b.svg)](http://arxiv.org/abs/2503.13952v1)|null|
|**2025-03-18**|**Robust3D-CIL: Robust Class-Incremental Learning for 3D Perception**|Jinge Ma et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13869v1-b31b1b.svg)](http://arxiv.org/abs/2503.13869v1)|null|
|**2025-03-17**|**A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives**|Weiqiang Jin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.13415v1-b31b1b.svg)](http://arxiv.org/abs/2503.13415v1)|null|
|**2025-03-17**|**SAM2 for Image and Video Segmentation: A Comprehensive Survey**|Zhang Jiaxing et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12781v1-b31b1b.svg)](http://arxiv.org/abs/2503.12781v1)|null|
|**2025-03-16**|**Logic-RAG: Augmenting Large Multimodal Models with Visual-Spatial Knowledge for Road Scene Understanding**|Imran Kabir et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12663v1-b31b1b.svg)](http://arxiv.org/abs/2503.12663v1)|null|
|**2025-03-16**|**Understanding Driver Cognition and Decision-Making Behaviors in High-Risk Scenarios: A Drift Diffusion Perspective**|Heye Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12637v1-b31b1b.svg)](http://arxiv.org/abs/2503.12637v1)|null|
|**2025-03-16**|**Towards Suturing World Models: Learning Predictive Models for Robotic Surgical Tasks**|Mehmet Kerem Turkcan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12531v1-b31b1b.svg)](http://arxiv.org/abs/2503.12531v1)|null|
|**2025-03-15**|**Bench2FreeAD: A Benchmark for Vision-based End-to-end Navigation in Unstructured Robotic Environments**|Yuhang Peng et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12180v1-b31b1b.svg)](http://arxiv.org/abs/2503.12180v1)|null|
|**2025-03-15**|**TACO: Taming Diffusion for in-the-wild Video Amodal Completion**|Ruijie Lu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.12049v1-b31b1b.svg)](http://arxiv.org/abs/2503.12049v1)|null|
|**2025-03-19**|**Controllable Latent Diffusion for Traffic Simulation**|Yizhuo Xiao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11771v2-b31b1b.svg)](http://arxiv.org/abs/2503.11771v2)|null|

