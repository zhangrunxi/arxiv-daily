---
layout: default
---

## Updated on 2025.06.11

## Autonomous_Driving_Planning

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-06-08**|**Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization**|Zhican Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07069v1-b31b1b.svg)](http://arxiv.org/abs/2506.07069v1)|null|
|**2025-06-07**|**Generalized Trajectory Scoring for End-to-end Multimodal Planning**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06664v1-b31b1b.svg)](http://arxiv.org/abs/2506.06664v1)|null|
|**2025-06-06**|**Trajectory Entropy: Modeling Game State Stability from Multimodality Trajectory Prediction**|Yesheng Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05810v1-b31b1b.svg)](http://arxiv.org/abs/2506.05810v1)|null|

## Autonomous_Driving_Prediction

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-06-08**|**Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization**|Zhican Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07069v1-b31b1b.svg)](http://arxiv.org/abs/2506.07069v1)|null|
|**2025-06-08**|**BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction**|Yunxiao Shi et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07002v1-b31b1b.svg)](http://arxiv.org/abs/2506.07002v1)|null|
|**2025-06-07**|**DONUT: A Decoder-Only Model for Trajectory Prediction**|Markus Knoche et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06854v1-b31b1b.svg)](http://arxiv.org/abs/2506.06854v1)|null|
|**2025-06-07**|**WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making**|Guillaume Levy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06725v1-b31b1b.svg)](http://arxiv.org/abs/2506.06725v1)|null|
|**2025-06-07**|**DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning**|Wenhao Yao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06659v1-b31b1b.svg)](http://arxiv.org/abs/2506.06659v1)|null|
|**2025-06-06**|**CCLSTM: Coupled Convolutional Long-Short Term Memory Network for Occupancy Flow Forecasting**|Peter Lengyel et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06128v1-b31b1b.svg)](http://arxiv.org/abs/2506.06128v1)|null|
|**2025-06-06**|**Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness**|Steven Landgraf et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05917v1-b31b1b.svg)](http://arxiv.org/abs/2506.05917v1)|null|
|**2025-06-06**|**Trajectory Entropy: Modeling Game State Stability from Multimodality Trajectory Prediction**|Yesheng Zhang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05810v1-b31b1b.svg)](http://arxiv.org/abs/2506.05810v1)|null|
|**2025-06-06**|**DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models**|Yuhan Hao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05667v1-b31b1b.svg)](http://arxiv.org/abs/2506.05667v1)|null|
|**2025-06-05**|**Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data**|Vlastimil Martinek et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05542v1-b31b1b.svg)](http://arxiv.org/abs/2506.05542v1)|null|

## Autonomous_Driving_Decision

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-06-09**|**UruBots Autonomous Cars Challenge Pro Team Description Paper for FIRA 2025**|Pablo Moraes et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07348v1-b31b1b.svg)](http://arxiv.org/abs/2506.07348v1)|null|
|**2025-06-07**|**Generalized Trajectory Scoring for End-to-end Multimodal Planning**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06664v1-b31b1b.svg)](http://arxiv.org/abs/2506.06664v1)|null|
|**2025-06-06**|**Edge-Enabled Collaborative Object Detection for Real-Time Multi-Vehicle Perception**|Everett Richards et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06474v1-b31b1b.svg)](http://arxiv.org/abs/2506.06474v1)|null|
|**2025-06-06**|**DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models**|Yuhan Hao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05667v1-b31b1b.svg)](http://arxiv.org/abs/2506.05667v1)|null|
|**2025-06-05**|**Structured Labeling Enables Faster Vision-Language Models for End-to-End Autonomous Driving**|Hao Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05442v1-b31b1b.svg)](http://arxiv.org/abs/2506.05442v1)|null|
|**2025-06-04**|**AD-EE: Early Exiting for Fast and Reliable Vision-Language Models in Autonomous Driving**|Lianming Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05404v1-b31b1b.svg)](http://arxiv.org/abs/2506.05404v1)|null|

## Autonomous_Driving_E2E

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-06-09**|**LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments**|Jin Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07416v1-b31b1b.svg)](http://arxiv.org/abs/2506.07416v1)|null|
|**2025-06-08**|**Hierarchical Feature-level Reverse Propagation for Post-Training Neural Networks**|Ni Ding et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07188v1-b31b1b.svg)](http://arxiv.org/abs/2506.07188v1)|null|
|**2025-06-08**|**UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment**|Wentao Zhao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07013v1-b31b1b.svg)](http://arxiv.org/abs/2506.07013v1)|null|
|**2025-06-07**|**Generalized Trajectory Scoring for End-to-end Multimodal Planning**|Zhenxin Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06664v1-b31b1b.svg)](http://arxiv.org/abs/2506.06664v1)|null|
|**2025-06-06**|**STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving**|Christian Fruhwirth-Reisinger et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06218v1-b31b1b.svg)](http://arxiv.org/abs/2506.06218v1)|null|
|**2025-06-06**|**CCLSTM: Coupled Convolutional Long-Short Term Memory Network for Occupancy Flow Forecasting**|Peter Lengyel et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06128v1-b31b1b.svg)](http://arxiv.org/abs/2506.06128v1)|null|
|**2025-06-06**|**Self driving algorithm for an active four wheel drive racecar**|Gergely Bari et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06077v1-b31b1b.svg)](http://arxiv.org/abs/2506.06077v1)|null|
|**2025-06-05**|**Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data**|Vlastimil Martinek et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05542v1-b31b1b.svg)](http://arxiv.org/abs/2506.05542v1)|null|
|**2025-06-05**|**Structured Labeling Enables Faster Vision-Language Models for End-to-End Autonomous Driving**|Hao Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05442v1-b31b1b.svg)](http://arxiv.org/abs/2506.05442v1)|null|

## Autonomous_Driving_LLM

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-06-09**|**LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments**|Jin Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07416v1-b31b1b.svg)](http://arxiv.org/abs/2506.07416v1)|null|
|**2025-06-07**|**WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making**|Guillaume Levy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06725v1-b31b1b.svg)](http://arxiv.org/abs/2506.06725v1)|null|
|**2025-06-05**|**VideoMolmo: Spatio-Temporal Grounding Meets Pointing**|Ghazi Shazan Ahmad et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05336v1-b31b1b.svg)](http://arxiv.org/abs/2506.05336v1)|null|

## Autonomous_Driving_RL

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-06-07**|**WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making**|Guillaume Levy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06725v1-b31b1b.svg)](http://arxiv.org/abs/2506.06725v1)|null|
|**2025-06-06**|**Self driving algorithm for an active four wheel drive racecar**|Gergely Bari et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06077v1-b31b1b.svg)](http://arxiv.org/abs/2506.06077v1)|null|
|**2025-06-05**|**Self-Predictive Dynamics for Generalization of Vision-based Reinforcement Learning**|Kyungsoo Kim et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05418v1-b31b1b.svg)](http://arxiv.org/abs/2506.05418v1)|null|
|**2025-06-04**|**Autonomous Vehicle Lateral Control Using Deep Reinforcement Learning with MPC-PID Demonstration**|Chengdong Wu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.04040v1-b31b1b.svg)](http://arxiv.org/abs/2506.04040v1)|null|
|**2025-06-05**|**Confidence-Guided Human-AI Collaboration: Reinforcement Learning with Distributional Proxy Value Propagation for Autonomous Driving**|Li Zeqiao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.03568v2-b31b1b.svg)](http://arxiv.org/abs/2506.03568v2)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/lzqw/c-hac)**|

## World_Model

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-06-09**|**ZeroVO: Visual Odometry with Minimal Assumptions**|Lei Lai et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.08005v1-b31b1b.svg)](http://arxiv.org/abs/2506.08005v1)|null|
|**2025-06-09**|**R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation**|William Ljungbergh et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07826v1-b31b1b.svg)](http://arxiv.org/abs/2506.07826v1)|null|
|**2025-06-08**|**Improving Traffic Signal Data Quality for the Waymo Open Motion Dataset**|Xintao Yan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.07150v1-b31b1b.svg)](http://arxiv.org/abs/2506.07150v1)|null|
|**2025-06-07**|**WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making**|Guillaume Levy et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.06725v1-b31b1b.svg)](http://arxiv.org/abs/2506.06725v1)|null|
|**2025-06-06**|**Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness**|Steven Landgraf et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05917v1-b31b1b.svg)](http://arxiv.org/abs/2506.05917v1)|null|
|**2025-06-06**|**DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models**|Yuhan Hao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05667v1-b31b1b.svg)](http://arxiv.org/abs/2506.05667v1)|null|
|**2025-06-05**|**Structured Labeling Enables Faster Vision-Language Models for End-to-End Autonomous Driving**|Hao Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05442v1-b31b1b.svg)](http://arxiv.org/abs/2506.05442v1)|null|
|**2025-06-05**|**VideoMolmo: Spatio-Temporal Grounding Meets Pointing**|Ghazi Shazan Ahmad et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05336v1-b31b1b.svg)](http://arxiv.org/abs/2506.05336v1)|null|
|**2025-06-06**|**Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting**|Nan Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.05280v2-b31b1b.svg)](http://arxiv.org/abs/2506.05280v2)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/bigcileng/bilateral-driving)**|
|**2025-06-05**|**Real-Time LPV-Based Non-Linear Model Predictive Control for Robust Trajectory Tracking in Autonomous Vehicles**|Nitish Kumar et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2506.04684v1-b31b1b.svg)](http://arxiv.org/abs/2506.04684v1)|null|

