> Updated on 2025.06.03

## Autonomous_Driving_Planning

- 2025-05-30, **SAH-Drive: A Scenario-Aware Hybrid Planner for Closed-Loop Vehicle Trajectory Generation**, Yuqi Fan et.al., Paper: [http://arxiv.org/abs/2505.24390v1](http://arxiv.org/abs/2505.24390v1)
- 2025-05-30, **DTR: Delaunay Triangulation-based Racing for Scaled Autonomous Racing**, Luca Tognoni et.al., Paper: [http://arxiv.org/abs/2505.24320v1](http://arxiv.org/abs/2505.24320v1)
- 2025-05-30, **S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation**, Yichen Xie et.al., Paper: [http://arxiv.org/abs/2505.24139v1](http://arxiv.org/abs/2505.24139v1)
- 2025-05-29, **Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models**, Haohan Chi et.al., Paper: [http://arxiv.org/abs/2505.23757v1](http://arxiv.org/abs/2505.23757v1), Code: **[https://github.com/ahydchh/impromptu-vla](https://github.com/ahydchh/impromptu-vla)**
- 2025-05-29, **Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving**, Yunshen Wang et.al., Paper: [http://arxiv.org/abs/2505.23115v1](http://arxiv.org/abs/2505.23115v1)
- 2025-05-29, **GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control**, Anthony Chen et.al., Paper: [http://arxiv.org/abs/2505.22421v2](http://arxiv.org/abs/2505.22421v2), Code: **[https://github.com/antonioo-c/geodrive](https://github.com/antonioo-c/geodrive)**
- 2025-05-27, **Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**, Muzhi Zhu et.al., Paper: [http://arxiv.org/abs/2505.21457v1](http://arxiv.org/abs/2505.21457v1)

## Autonomous_Driving_Prediction

- 2025-05-30, **S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation**, Yichen Xie et.al., Paper: [http://arxiv.org/abs/2505.24139v1](http://arxiv.org/abs/2505.24139v1)
- 2025-05-29, **Towards Understanding The Calibration Benefits of Sharpness-Aware Minimization**, Chengli Tan et.al., Paper: [http://arxiv.org/abs/2505.23866v1](http://arxiv.org/abs/2505.23866v1)
- 2025-05-29, **Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models**, Haohan Chi et.al., Paper: [http://arxiv.org/abs/2505.23757v1](http://arxiv.org/abs/2505.23757v1), Code: **[https://github.com/ahydchh/impromptu-vla](https://github.com/ahydchh/impromptu-vla)**
- 2025-05-29, **Autoregressive Meta-Actions for Unified Controllable Trajectory Generation**, Jianbo Zhao et.al., Paper: [http://arxiv.org/abs/2505.23612v1](http://arxiv.org/abs/2505.23612v1)
- 2025-05-29, **Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving**, Yunshen Wang et.al., Paper: [http://arxiv.org/abs/2505.23115v1](http://arxiv.org/abs/2505.23115v1)
- 2025-05-28, **A Human-Centric Approach to Explainable AI for Personalized Education**, Vinitra Swamy et.al., Paper: [http://arxiv.org/abs/2505.22541v1](http://arxiv.org/abs/2505.22541v1), Code: **[https://github.com/epfl-ml4ed/interpretcc](https://github.com/epfl-ml4ed/interpretcc)**
- 2025-05-29, **The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector**, Aixuan Li et.al., Paper: [http://arxiv.org/abs/2505.22499v2](http://arxiv.org/abs/2505.22499v2)
- 2025-05-29, **SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels**, Qiucheng Yu et.al., Paper: [http://arxiv.org/abs/2505.22461v2](http://arxiv.org/abs/2505.22461v2)
- 2025-05-28, **LiDARDustX: A LiDAR Dataset for Dusty Unstructured Road Environments**, Chenfeng Wei et.al., Paper: [http://arxiv.org/abs/2505.21914v1](http://arxiv.org/abs/2505.21914v1)

## Autonomous_Driving_Decision

- 2025-05-30, **Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks**, Tajamul Ashraf et.al., Paper: [http://arxiv.org/abs/2505.24876v1](http://arxiv.org/abs/2505.24876v1)
- 2025-05-30, **SAH-Drive: A Scenario-Aware Hybrid Planner for Closed-Loop Vehicle Trajectory Generation**, Yuqi Fan et.al., Paper: [http://arxiv.org/abs/2505.24390v1](http://arxiv.org/abs/2505.24390v1)
- 2025-05-30, **ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving**, Yongming Chen et.al., Paper: [http://arxiv.org/abs/2505.24317v1](http://arxiv.org/abs/2505.24317v1)
- 2025-05-29, **Autoregressive Meta-Actions for Unified Controllable Trajectory Generation**, Jianbo Zhao et.al., Paper: [http://arxiv.org/abs/2505.23612v1](http://arxiv.org/abs/2505.23612v1)
- 2025-05-29, **Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception**, Guangyuan Liu et.al., Paper: [http://arxiv.org/abs/2505.23275v1](http://arxiv.org/abs/2505.23275v1)
- 2025-05-28, **A Human-Centric Approach to Explainable AI for Personalized Education**, Vinitra Swamy et.al., Paper: [http://arxiv.org/abs/2505.22541v1](http://arxiv.org/abs/2505.22541v1), Code: **[https://github.com/epfl-ml4ed/interpretcc](https://github.com/epfl-ml4ed/interpretcc)**
- 2025-05-28, **An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints**, Jiahui Zhu et.al., Paper: [http://arxiv.org/abs/2505.21841v1](http://arxiv.org/abs/2505.21841v1)
- 2025-05-27, **Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**, Muzhi Zhu et.al., Paper: [http://arxiv.org/abs/2505.21457v1](http://arxiv.org/abs/2505.21457v1)

## Autonomous_Driving_E2E

- 2025-05-30, **DTR: Delaunay Triangulation-based Racing for Scaled Autonomous Racing**, Luca Tognoni et.al., Paper: [http://arxiv.org/abs/2505.24320v1](http://arxiv.org/abs/2505.24320v1)
- 2025-05-30, **S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation**, Yichen Xie et.al., Paper: [http://arxiv.org/abs/2505.24139v1](http://arxiv.org/abs/2505.24139v1)
- 2025-05-29, **HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring**, Bin Wang et.al., Paper: [http://arxiv.org/abs/2505.23129v1](http://arxiv.org/abs/2505.23129v1)
- 2025-05-28, **Learnable Burst-Encodable Time-of-Flight Imaging for High-Fidelity Long-Distance Depth Sensing**, Manchao Bao et.al., Paper: [http://arxiv.org/abs/2505.22025v1](http://arxiv.org/abs/2505.22025v1)
- 2025-06-02, **A first look at ROS 2 applications written in asynchronous Rust**, Martin Å koudlil et.al., Paper: [http://arxiv.org/abs/2505.21323v2](http://arxiv.org/abs/2505.21323v2)

## Autonomous_Driving_LLM

- 2025-05-29, **Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception**, Guangyuan Liu et.al., Paper: [http://arxiv.org/abs/2505.23275v1](http://arxiv.org/abs/2505.23275v1)
- 2025-05-29, **Context-Aware Semantic Communication for the Wireless Networks**, Guangyuan Liu et.al., Paper: [http://arxiv.org/abs/2505.23249v1](http://arxiv.org/abs/2505.23249v1)
- 2025-05-28, **A Human-Centric Approach to Explainable AI for Personalized Education**, Vinitra Swamy et.al., Paper: [http://arxiv.org/abs/2505.22541v1](http://arxiv.org/abs/2505.22541v1), Code: **[https://github.com/epfl-ml4ed/interpretcc](https://github.com/epfl-ml4ed/interpretcc)**
- 2025-05-28, **From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving**, Xinyu Xia et.al., Paper: [http://arxiv.org/abs/2505.22067v1](http://arxiv.org/abs/2505.22067v1)

## Autonomous_Driving_RL

- 2025-05-30, **ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving**, Yongming Chen et.al., Paper: [http://arxiv.org/abs/2505.24317v1](http://arxiv.org/abs/2505.24317v1)
- 2025-05-29, **Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception**, Guangyuan Liu et.al., Paper: [http://arxiv.org/abs/2505.23275v1](http://arxiv.org/abs/2505.23275v1)
- 2025-05-29, **Context-Aware Semantic Communication for the Wireless Networks**, Guangyuan Liu et.al., Paper: [http://arxiv.org/abs/2505.23249v1](http://arxiv.org/abs/2505.23249v1)
- 2025-05-28, **An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints**, Jiahui Zhu et.al., Paper: [http://arxiv.org/abs/2505.21841v1](http://arxiv.org/abs/2505.21841v1)
- 2025-05-27, **Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**, Muzhi Zhu et.al., Paper: [http://arxiv.org/abs/2505.21457v1](http://arxiv.org/abs/2505.21457v1)

## World_Model

- 2025-05-30, **Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks**, Tajamul Ashraf et.al., Paper: [http://arxiv.org/abs/2505.24876v1](http://arxiv.org/abs/2505.24876v1)
- 2025-05-30, **Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation**, Roger Ferrod et.al., Paper: [http://arxiv.org/abs/2505.24361v1](http://arxiv.org/abs/2505.24361v1)
- 2025-05-29, **Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving**, Yunshen Wang et.al., Paper: [http://arxiv.org/abs/2505.23115v1](http://arxiv.org/abs/2505.23115v1)
- 2025-05-28, **A Human-Centric Approach to Explainable AI for Personalized Education**, Vinitra Swamy et.al., Paper: [http://arxiv.org/abs/2505.22541v1](http://arxiv.org/abs/2505.22541v1), Code: **[https://github.com/epfl-ml4ed/interpretcc](https://github.com/epfl-ml4ed/interpretcc)**
- 2025-05-29, **The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector**, Aixuan Li et.al., Paper: [http://arxiv.org/abs/2505.22499v2](http://arxiv.org/abs/2505.22499v2)
- 2025-05-29, **GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control**, Anthony Chen et.al., Paper: [http://arxiv.org/abs/2505.22421v2](http://arxiv.org/abs/2505.22421v2), Code: **[https://github.com/antonioo-c/geodrive](https://github.com/antonioo-c/geodrive)**
- 2025-05-27, **Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO**, Muzhi Zhu et.al., Paper: [http://arxiv.org/abs/2505.21457v1](http://arxiv.org/abs/2505.21457v1)

