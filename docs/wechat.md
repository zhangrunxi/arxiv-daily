> Updated on 2025.01.18

## Autonomous_Driving_Planning

- 2025-01-16, **Distilling Multi-modal Large Language Models for Autonomous Driving**, Deepti Hegde et.al., Paper: [http://arxiv.org/abs/2501.09757v1](http://arxiv.org/abs/2501.09757v1)
- 2025-01-15, **Generative Planning with 3D-vision Language Pre-training for End-to-End Autonomous Driving**, Tengpeng Li et.al., Paper: [http://arxiv.org/abs/2501.08861v1](http://arxiv.org/abs/2501.08861v1)
- 2025-01-12, **Application of Vision-Language Model to Pedestrians Behavior and Scene Understanding in Autonomous Driving**, Haoxiang Gao et.al., Paper: [http://arxiv.org/abs/2501.06680v1](http://arxiv.org/abs/2501.06680v1)

## Autonomous_Driving_Prediction

- 2025-01-16, **Thermodynamics of coherent energy exchanges between lasers and two-level systems**, Ariane Soret et.al., Paper: [http://arxiv.org/abs/2501.09625v1](http://arxiv.org/abs/2501.09625v1)
- 2025-01-14, **GAC-Net_Geometric and attention-based Network for Depth Completion**, Kuang Zhu et.al., Paper: [http://arxiv.org/abs/2501.07988v1](http://arxiv.org/abs/2501.07988v1)
- 2025-01-13, **Explore the Use of Time Series Foundation Model for Car-Following Behavior Analysis**, Luwei Zeng et.al., Paper: [http://arxiv.org/abs/2501.07034v1](http://arxiv.org/abs/2501.07034v1)

## Autonomous_Driving_Decision

- 2025-01-16, **On Learning Informative Trajectory Embeddings for Imitation, Classification and Regression**, Zichang Ge et.al., Paper: [http://arxiv.org/abs/2501.09327v1](http://arxiv.org/abs/2501.09327v1), Code: **[https://github.com/erasmo1015/vte](https://github.com/erasmo1015/vte)**
- 2025-01-15, **Generative Planning with 3D-vision Language Pre-training for End-to-End Autonomous Driving**, Tengpeng Li et.al., Paper: [http://arxiv.org/abs/2501.08861v1](http://arxiv.org/abs/2501.08861v1)
- 2025-01-14, **Automotive Elevation Mapping with Interferometric Synthetic Aperture Radar**, Leyla A. Kabuli et.al., Paper: [http://arxiv.org/abs/2501.08495v1](http://arxiv.org/abs/2501.08495v1)
- 2025-01-14, **Decoding Interpretable Logic Rules from Neural Networks**, Chuqin Geng et.al., Paper: [http://arxiv.org/abs/2501.08281v1](http://arxiv.org/abs/2501.08281v1)
- 2025-01-14, **LeapVAD: A Leap in Autonomous Driving via Cognitive Perception and Dual-Process Thinking**, Yukai Ma et.al., Paper: [http://arxiv.org/abs/2501.08168v1](http://arxiv.org/abs/2501.08168v1)
- 2025-01-14, **Hybrid Action Based Reinforcement Learning for Multi-Objective Compatible Autonomous Driving**, Guizhe Jin et.al., Paper: [http://arxiv.org/abs/2501.08096v1](http://arxiv.org/abs/2501.08096v1)
- 2025-01-16, **PO-GVINS: Tightly Coupled GNSS-Visual-Inertial Integration with Pose-Only Representation**, Zhuo Xu et.al., Paper: [http://arxiv.org/abs/2501.07259v2](http://arxiv.org/abs/2501.07259v2)
- 2025-01-12, **Application of Vision-Language Model to Pedestrians Behavior and Scene Understanding in Autonomous Driving**, Haoxiang Gao et.al., Paper: [http://arxiv.org/abs/2501.06680v1](http://arxiv.org/abs/2501.06680v1)

## Autonomous_Driving_E2E

- 2025-01-16, **Distilling Multi-modal Large Language Models for Autonomous Driving**, Deepti Hegde et.al., Paper: [http://arxiv.org/abs/2501.09757v1](http://arxiv.org/abs/2501.09757v1)
- 2025-01-15, **Generative Planning with 3D-vision Language Pre-training for End-to-End Autonomous Driving**, Tengpeng Li et.al., Paper: [http://arxiv.org/abs/2501.08861v1](http://arxiv.org/abs/2501.08861v1)
- 2025-01-16, **BRIGHT-VO: Brightness-Guided Hybrid Transformer for Visual Odometry with Multi-modality Refinement Module**, Dongzhihan Wang et.al., Paper: [http://arxiv.org/abs/2501.08659v2](http://arxiv.org/abs/2501.08659v2)
- 2025-01-14, **Hybrid Action Based Reinforcement Learning for Multi-Objective Compatible Autonomous Driving**, Guizhe Jin et.al., Paper: [http://arxiv.org/abs/2501.08096v1](http://arxiv.org/abs/2501.08096v1)
- 2025-01-14, **HgPCN: A Heterogeneous Architecture for E2E Embedded Point Cloud Inference**, Yiming Gao et.al., Paper: [http://arxiv.org/abs/2501.07767v1](http://arxiv.org/abs/2501.07767v1)

## Autonomous_Driving_LLM

- 2025-01-16, **Distilling Multi-modal Large Language Models for Autonomous Driving**, Deepti Hegde et.al., Paper: [http://arxiv.org/abs/2501.09757v1](http://arxiv.org/abs/2501.09757v1)
- 2025-01-12, **Application of Vision-Language Model to Pedestrians Behavior and Scene Understanding in Autonomous Driving**, Haoxiang Gao et.al., Paper: [http://arxiv.org/abs/2501.06680v1](http://arxiv.org/abs/2501.06680v1)

## Autonomous_Driving_RL

- 2025-01-16, **RE-POSE: Synergizing Reinforcement Learning-Based Partitioning and Offloading for Edge Object Detection**, Jianrui Shi et.al., Paper: [http://arxiv.org/abs/2501.09465v1](http://arxiv.org/abs/2501.09465v1)
- 2025-01-14, **Hybrid Action Based Reinforcement Learning for Multi-Objective Compatible Autonomous Driving**, Guizhe Jin et.al., Paper: [http://arxiv.org/abs/2501.08096v1](http://arxiv.org/abs/2501.08096v1)

## World_Model

- 2025-01-16, **Distilling Multi-modal Large Language Models for Autonomous Driving**, Deepti Hegde et.al., Paper: [http://arxiv.org/abs/2501.09757v1](http://arxiv.org/abs/2501.09757v1)
- 2025-01-16, **On Learning Informative Trajectory Embeddings for Imitation, Classification and Regression**, Zichang Ge et.al., Paper: [http://arxiv.org/abs/2501.09327v1](http://arxiv.org/abs/2501.09327v1), Code: **[https://github.com/erasmo1015/vte](https://github.com/erasmo1015/vte)**
- 2025-01-11, **Common Sense Is All You Need**, Hugo Latapie et.al., Paper: [http://arxiv.org/abs/2501.06642v1](http://arxiv.org/abs/2501.06642v1)

