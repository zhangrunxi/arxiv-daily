{"Autonomous_Driving_Planning": {"2505.17732": "- 2025-05-23, **RQR3D: Reparametrizing the regression targets for BEV-based 3D object detection**, Ozsel Kilinc et.al., Paper: [http://arxiv.org/abs/2505.17732v1](http://arxiv.org/abs/2505.17732v1)\n", "2505.17727": "- 2025-05-23, **SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**, Jiawei Zhou et.al., Paper: [http://arxiv.org/abs/2505.17727v1](http://arxiv.org/abs/2505.17727v1)\n", "2505.17685": "- 2025-05-23, **FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving**, Shuang Zeng et.al., Paper: [http://arxiv.org/abs/2505.17685v1](http://arxiv.org/abs/2505.17685v1)\n", "2505.17659": "- 2025-05-23, **Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**, Xiaolong Tang et.al., Paper: [http://arxiv.org/abs/2505.17659v1](http://arxiv.org/abs/2505.17659v1)\n", "2505.17209": "- 2025-05-22, **LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios**, Huaiyuan Yao et.al., Paper: [http://arxiv.org/abs/2505.17209v1](http://arxiv.org/abs/2505.17209v1)\n", "2505.16805": "- 2025-05-22, **SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**, Xuesong Chen et.al., Paper: [http://arxiv.org/abs/2505.16805v1](http://arxiv.org/abs/2505.16805v1)\n", "2505.16524": "- 2025-05-22, **CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving**, Huitong Yang et.al., Paper: [http://arxiv.org/abs/2505.16524v1](http://arxiv.org/abs/2505.16524v1)\n", "2505.16498": "- 2025-05-22, **Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models**, Augusto Luis Ballardini et.al., Paper: [http://arxiv.org/abs/2505.16498v1](http://arxiv.org/abs/2505.16498v1)\n", "2505.16394": "- 2025-05-22, **Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**, Zhenjie Yang et.al., Paper: [http://arxiv.org/abs/2505.16394v1](http://arxiv.org/abs/2505.16394v1)\n", "2505.16377": "- 2025-05-22, **VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving**, Yansong Qu et.al., Paper: [http://arxiv.org/abs/2505.16377v1](http://arxiv.org/abs/2505.16377v1)\n"}, "Autonomous_Driving_Prediction": {"2505.17801": "- 2025-05-23, **Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour**, B\u00e1lint Gyevn\u00e1r et.al., Paper: [http://arxiv.org/abs/2505.17801v1](http://arxiv.org/abs/2505.17801v1)\n", "2505.17685": "- 2025-05-23, **FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving**, Shuang Zeng et.al., Paper: [http://arxiv.org/abs/2505.17685v1](http://arxiv.org/abs/2505.17685v1)\n", "2505.17659": "- 2025-05-23, **Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**, Xiaolong Tang et.al., Paper: [http://arxiv.org/abs/2505.17659v1](http://arxiv.org/abs/2505.17659v1)\n", "2505.16985": "- 2025-05-22, **Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation**, Moru Liu et.al., Paper: [http://arxiv.org/abs/2505.16985v1](http://arxiv.org/abs/2505.16985v1), Code: **[https://github.com/mona4399/featuremixing](https://github.com/mona4399/featuremixing)**\n", "2505.16938": "- 2025-05-22, **NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification**, NovelSeek Team et.al., Paper: [http://arxiv.org/abs/2505.16938v1](http://arxiv.org/abs/2505.16938v1)\n", "2505.16805": "- 2025-05-22, **SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**, Xuesong Chen et.al., Paper: [http://arxiv.org/abs/2505.16805v1](http://arxiv.org/abs/2505.16805v1)\n", "2505.16524": "- 2025-05-22, **CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving**, Huitong Yang et.al., Paper: [http://arxiv.org/abs/2505.16524v1](http://arxiv.org/abs/2505.16524v1)\n", "2505.15925": "- 2025-05-21, **VERDI: VLM-Embedded Reasoning for Autonomous Driving**, Bowen Feng et.al., Paper: [http://arxiv.org/abs/2505.15925v1](http://arxiv.org/abs/2505.15925v1)\n", "2505.15703": "- 2025-05-21, **HAMF: A Hybrid Attention-Mamba Framework for Joint Scene Context Understanding and Future Motion Representation Learning**, Xiaodong Mei et.al., Paper: [http://arxiv.org/abs/2505.15703v1](http://arxiv.org/abs/2505.15703v1)\n", "2505.15158": "- 2025-05-21, **ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving**, Yunsheng Ma et.al., Paper: [http://arxiv.org/abs/2505.15158v1](http://arxiv.org/abs/2505.15158v1)\n"}, "Autonomous_Driving_Decision": {"2505.16805": "- 2025-05-22, **SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**, Xuesong Chen et.al., Paper: [http://arxiv.org/abs/2505.16805v1](http://arxiv.org/abs/2505.16805v1)\n", "2505.16498": "- 2025-05-22, **Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models**, Augusto Luis Ballardini et.al., Paper: [http://arxiv.org/abs/2505.16498v1](http://arxiv.org/abs/2505.16498v1)\n", "2505.15925": "- 2025-05-21, **VERDI: VLM-Embedded Reasoning for Autonomous Driving**, Bowen Feng et.al., Paper: [http://arxiv.org/abs/2505.15925v1](http://arxiv.org/abs/2505.15925v1)\n", "2505.15304": "- 2025-05-21, **Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control**, Seongmin Park et.al., Paper: [http://arxiv.org/abs/2505.15304v1](http://arxiv.org/abs/2505.15304v1)\n", "2505.15158": "- 2025-05-21, **ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving**, Yunsheng Ma et.al., Paper: [http://arxiv.org/abs/2505.15158v1](http://arxiv.org/abs/2505.15158v1)\n", "2505.14842": "- 2025-05-20, **Looking for an out: Affordances, uncertainty and collision avoidance behavior of human drivers**, Leif Johnson et.al., Paper: [http://arxiv.org/abs/2505.14842v1](http://arxiv.org/abs/2505.14842v1)\n"}, "Autonomous_Driving_E2E": {"2505.17727": "- 2025-05-23, **SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**, Jiawei Zhou et.al., Paper: [http://arxiv.org/abs/2505.17727v1](http://arxiv.org/abs/2505.17727v1)\n", "2505.16938": "- 2025-05-22, **NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification**, NovelSeek Team et.al., Paper: [http://arxiv.org/abs/2505.16938v1](http://arxiv.org/abs/2505.16938v1)\n", "2505.16805": "- 2025-05-22, **SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**, Xuesong Chen et.al., Paper: [http://arxiv.org/abs/2505.16805v1](http://arxiv.org/abs/2505.16805v1)\n", "2505.16524": "- 2025-05-22, **CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving**, Huitong Yang et.al., Paper: [http://arxiv.org/abs/2505.16524v1](http://arxiv.org/abs/2505.16524v1)\n", "2505.16394": "- 2025-05-22, **Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**, Zhenjie Yang et.al., Paper: [http://arxiv.org/abs/2505.16394v1](http://arxiv.org/abs/2505.16394v1)\n", "2505.16278": "- 2025-05-22, **DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving**, Zhenjie Yang et.al., Paper: [http://arxiv.org/abs/2505.16278v1](http://arxiv.org/abs/2505.16278v1)\n", "2505.15925": "- 2025-05-21, **VERDI: VLM-Embedded Reasoning for Autonomous Driving**, Bowen Feng et.al., Paper: [http://arxiv.org/abs/2505.15925v1](http://arxiv.org/abs/2505.15925v1)\n", "2505.15880": "- 2025-05-23, **Challenger: Affordable Adversarial Driving Video Generation**, Zhiyuan Xu et.al., Paper: [http://arxiv.org/abs/2505.15880v2](http://arxiv.org/abs/2505.15880v2)\n", "2505.15275": "- 2025-05-21, **Learning-based Autonomous Oversteer Control and Collision Avoidance**, Seokjun Lee et.al., Paper: [http://arxiv.org/abs/2505.15275v1](http://arxiv.org/abs/2505.15275v1)\n", "2505.15158": "- 2025-05-21, **ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving**, Yunsheng Ma et.al., Paper: [http://arxiv.org/abs/2505.15158v1](http://arxiv.org/abs/2505.15158v1)\n"}, "Autonomous_Driving_LLM": {"2505.17801": "- 2025-05-23, **Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour**, B\u00e1lint Gyevn\u00e1r et.al., Paper: [http://arxiv.org/abs/2505.17801v1](http://arxiv.org/abs/2505.17801v1)\n", "2505.17209": "- 2025-05-22, **LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios**, Huaiyuan Yao et.al., Paper: [http://arxiv.org/abs/2505.17209v1](http://arxiv.org/abs/2505.17209v1)\n", "2505.16498": "- 2025-05-22, **Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models**, Augusto Luis Ballardini et.al., Paper: [http://arxiv.org/abs/2505.16498v1](http://arxiv.org/abs/2505.16498v1)\n", "2505.16278": "- 2025-05-22, **DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving**, Zhenjie Yang et.al., Paper: [http://arxiv.org/abs/2505.16278v1](http://arxiv.org/abs/2505.16278v1)\n", "2505.15793": "- 2025-05-22, **HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving**, Zhiwen Chen et.al., Paper: [http://arxiv.org/abs/2505.15793v2](http://arxiv.org/abs/2505.15793v2)\n", "2505.15269": "- 2025-05-21, **LiveVLM: Efficient Online Video Understanding via Streaming-Oriented KV Cache and Retrieval**, Zhenyu Ning et.al., Paper: [http://arxiv.org/abs/2505.15269v1](http://arxiv.org/abs/2505.15269v1)\n", "2505.15158": "- 2025-05-21, **ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving**, Yunsheng Ma et.al., Paper: [http://arxiv.org/abs/2505.15158v1](http://arxiv.org/abs/2505.15158v1)\n", "2505.14948": "- 2025-05-20, **Programmatic Video Prediction Using Large Language Models**, Hao Tang et.al., Paper: [http://arxiv.org/abs/2505.14948v1](http://arxiv.org/abs/2505.14948v1), Code: **[https://github.com/metro-smiles/ProgGen](https://github.com/metro-smiles/ProgGen)**\n"}, "Autonomous_Driving_RL": {"2505.17801": "- 2025-05-23, **Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour**, B\u00e1lint Gyevn\u00e1r et.al., Paper: [http://arxiv.org/abs/2505.17801v1](http://arxiv.org/abs/2505.17801v1)\n", "2505.17659": "- 2025-05-23, **Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**, Xiaolong Tang et.al., Paper: [http://arxiv.org/abs/2505.17659v1](http://arxiv.org/abs/2505.17659v1)\n", "2505.16394": "- 2025-05-22, **Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**, Zhenjie Yang et.al., Paper: [http://arxiv.org/abs/2505.16394v1](http://arxiv.org/abs/2505.16394v1)\n", "2505.16377": "- 2025-05-22, **VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving**, Yansong Qu et.al., Paper: [http://arxiv.org/abs/2505.16377v1](http://arxiv.org/abs/2505.16377v1)\n", "2505.15793": "- 2025-05-22, **HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving**, Zhiwen Chen et.al., Paper: [http://arxiv.org/abs/2505.15793v2](http://arxiv.org/abs/2505.15793v2)\n", "2505.15275": "- 2025-05-21, **Learning-based Autonomous Oversteer Control and Collision Avoidance**, Seokjun Lee et.al., Paper: [http://arxiv.org/abs/2505.15275v1](http://arxiv.org/abs/2505.15275v1)\n"}, "World_Model": {"2505.18039": "- 2025-05-23, **Clip4Retrofit: Enabling Real-Time Image Labeling on Edge Devices via Cross-Architecture CLIP Distillation**, Li Zhong et.al., Paper: [http://arxiv.org/abs/2505.18039v1](http://arxiv.org/abs/2505.18039v1)\n", "2505.17727": "- 2025-05-23, **SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**, Jiawei Zhou et.al., Paper: [http://arxiv.org/abs/2505.17727v1](http://arxiv.org/abs/2505.17727v1)\n", "2505.17695": "- 2025-05-23, **SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data**, Dong-Hee Kim et.al., Paper: [http://arxiv.org/abs/2505.17695v1](http://arxiv.org/abs/2505.17695v1)\n", "2505.17685": "- 2025-05-23, **FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving**, Shuang Zeng et.al., Paper: [http://arxiv.org/abs/2505.17685v1](http://arxiv.org/abs/2505.17685v1)\n", "2505.17659": "- 2025-05-23, **Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling**, Xiaolong Tang et.al., Paper: [http://arxiv.org/abs/2505.17659v1](http://arxiv.org/abs/2505.17659v1)\n", "2505.17275": "- 2025-05-22, **ConvoyNext: A Scalable Testbed Platform for Cooperative Autonomous Vehicle Systems**, Hossein Maghsoumi et.al., Paper: [http://arxiv.org/abs/2505.17275v1](http://arxiv.org/abs/2505.17275v1)\n", "2505.17209": "- 2025-05-22, **LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios**, Huaiyuan Yao et.al., Paper: [http://arxiv.org/abs/2505.17209v1](http://arxiv.org/abs/2505.17209v1)\n", "2505.16985": "- 2025-05-22, **Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation**, Moru Liu et.al., Paper: [http://arxiv.org/abs/2505.16985v1](http://arxiv.org/abs/2505.16985v1), Code: **[https://github.com/mona4399/featuremixing](https://github.com/mona4399/featuremixing)**\n", "2505.16498": "- 2025-05-22, **Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models**, Augusto Luis Ballardini et.al., Paper: [http://arxiv.org/abs/2505.16498v1](http://arxiv.org/abs/2505.16498v1)\n", "2505.16394": "- 2025-05-22, **Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**, Zhenjie Yang et.al., Paper: [http://arxiv.org/abs/2505.16394v1](http://arxiv.org/abs/2505.16394v1)\n"}}