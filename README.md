## Updated on 2025.03.17

## Autonomous_Driving_Planning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving**|Tin Stribor Sohn et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11400v1-b31b1b.svg)](http://arxiv.org/abs/2503.11400v1)|null|
|**2025-03-13**|**DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10621v1-b31b1b.svg)](http://arxiv.org/abs/2503.10621v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ayesha-ishaq/drivelmm-o1)**|
|**2025-03-13**|**Finetuning Generative Trajectory Model with Reinforcement Learning from Human Feedback**|Derun Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10434v1-b31b1b.svg)](http://arxiv.org/abs/2503.10434v1)|null|
|**2025-03-12**|**Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latant Space**|Jian Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09215v1-b31b1b.svg)](http://arxiv.org/abs/2503.09215v1)|null|
|**2025-03-11**|**CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving**|Changxing Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08683v1-b31b1b.svg)](http://arxiv.org/abs/2503.08683v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/cxliu0314/colmdriver)**|
|**2025-03-11**|**Task-Oriented Co-Design of Communication, Computing, and Control for Edge-Enabled Industrial Cyber-Physical Systems**|Yufeng Diao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08661v1-b31b1b.svg)](http://arxiv.org/abs/2503.08661v1)|null|
|**2025-03-11**|**HiP-AD: Hierarchical and Multi-Granularity Planning with Deformable Attention for Autonomous Driving in a Single Decoder**|Yingqi Tang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08612v1-b31b1b.svg)](http://arxiv.org/abs/2503.08612v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/nullmax-vision/hip-ad)**|
|**2025-03-11**|**FASIONAD++ : Integrating High-Level Instruction and Information Bottleneck in FAt-Slow fusION Systems for Enhanced Safety in Autonomous Driving with Adaptive Feedback**|Kangan Qian et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08162v1-b31b1b.svg)](http://arxiv.org/abs/2503.08162v1)|null|
|**2025-03-10**|**AlphaDrive: Unleashing the Power of VLMs in Autonomous Driving via Reinforcement Learning and Reasoning**|Bo Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.07608v1-b31b1b.svg)](http://arxiv.org/abs/2503.07608v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/hustvl/alphadrive)**|

## Autonomous_Driving_Prediction

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**Learning-Based MPC for Efficient Control of Autonomous Vehicles**|Samuel Mallick et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11359v1-b31b1b.svg)](http://arxiv.org/abs/2503.11359v1)|null|
|**2025-03-13**|**Trajectory Mamba: Efficient Attention-Mamba Forecasting Model Based on Selective SSM**|Yizhou Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10898v1-b31b1b.svg)](http://arxiv.org/abs/2503.10898v1)|null|
|**2025-03-13**|**DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10621v1-b31b1b.svg)](http://arxiv.org/abs/2503.10621v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ayesha-ishaq/drivelmm-o1)**|
|**2025-03-13**|**OCCUQ: Exploring Efficient Uncertainty Quantification for 3D Occupancy Prediction**|Severin Heidrich et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10605v1-b31b1b.svg)](http://arxiv.org/abs/2503.10605v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ika-rwth-aachen/occuq)**|
|**2025-03-13**|**Mamba-VA: A Mamba-based Approach for Continuous Emotion Recognition in Valence-Arousal Space**|Yuheng Liang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10104v1-b31b1b.svg)](http://arxiv.org/abs/2503.10104v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/freedompuppy77/charon)**|
|**2025-03-13**|**TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points for 3D Environment Awareness**|Mu Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09941v1-b31b1b.svg)](http://arxiv.org/abs/2503.09941v1)|null|
|**2025-03-12**|**CleverDistiller: Simple and Spatially Consistent Cross-modal Distillation**|Hariprasath Govindarajan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09878v1-b31b1b.svg)](http://arxiv.org/abs/2503.09878v1)|null|
|**2025-03-12**|**Hybrid Rendering for Multimodal Autonomous Driving: Merging Neural and Physics-Based Simulation**|Máté Tóth et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09464v1-b31b1b.svg)](http://arxiv.org/abs/2503.09464v1)|null|
|**2025-03-12**|**Post-interactive Multimodal Trajectory Prediction for Autonomous Driving**|Ziyi Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09366v1-b31b1b.svg)](http://arxiv.org/abs/2503.09366v1)|null|

## Autonomous_Driving_Decision

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving**|Tin Stribor Sohn et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11400v1-b31b1b.svg)](http://arxiv.org/abs/2503.11400v1)|null|
|**2025-03-14**|**Active Learning from Scene Embeddings for End-to-End Autonomous Driving**|Wenhao Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11062v1-b31b1b.svg)](http://arxiv.org/abs/2503.11062v1)|null|
|**2025-03-13**|**DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding**|Ayesha Ishaq et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10621v1-b31b1b.svg)](http://arxiv.org/abs/2503.10621v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ayesha-ishaq/drivelmm-o1)**|
|**2025-03-12**|**Edge AI-Powered Real-Time Decision-Making for Autonomous Vehicles in Adverse Weather Conditions**|Milad Rahmati et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09638v1-b31b1b.svg)](http://arxiv.org/abs/2503.09638v1)|null|
|**2025-03-11**|**CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving**|Changxing Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08683v1-b31b1b.svg)](http://arxiv.org/abs/2503.08683v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/cxliu0314/colmdriver)**|
|**2025-03-11**|**V-Max: Making RL practical for Autonomous Driving**|Valentin Charraut et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08388v1-b31b1b.svg)](http://arxiv.org/abs/2503.08388v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/valeoai/v-max)**|
|**2025-03-11**|**FASIONAD++ : Integrating High-Level Instruction and Information Bottleneck in FAt-Slow fusION Systems for Enhanced Safety in Autonomous Driving with Adaptive Feedback**|Kangan Qian et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08162v1-b31b1b.svg)](http://arxiv.org/abs/2503.08162v1)|null|
|**2025-03-11**|**SGNetPose+: Stepwise Goal-Driven Networks with Pose Information for Trajectory Prediction in Autonomous Driving**|Akshat Ghiya et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08016v1-b31b1b.svg)](http://arxiv.org/abs/2503.08016v1)|null|
|**2025-03-10**|**Advances in Hybrid Modular Climbing Robots: Design Principles and Refinement Strategies**|Ryan Poon et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.07423v1-b31b1b.svg)](http://arxiv.org/abs/2503.07423v1)|null|

## Autonomous_Driving_E2E

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-14**|**Centaur: Robust End-to-End Autonomous Driving with Test-Time Training**|Chonghao Sima et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11650v1-b31b1b.svg)](http://arxiv.org/abs/2503.11650v1)|null|
|**2025-03-14**|**BEVDiffLoc: End-to-End LiDAR Global Localization in BEV View based on Diffusion Model**|Ziyue Wang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11372v1-b31b1b.svg)](http://arxiv.org/abs/2503.11372v1)|null|
|**2025-03-14**|**DynRsl-VLM: Enhancing Autonomous Driving Perception with Dynamic Resolution Vision-Language Models**|Xirui Zhou et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11265v1-b31b1b.svg)](http://arxiv.org/abs/2503.11265v1)|null|
|**2025-03-14**|**Active Learning from Scene Embeddings for End-to-End Autonomous Driving**|Wenhao Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11062v1-b31b1b.svg)](http://arxiv.org/abs/2503.11062v1)|null|
|**2025-03-12**|**Post-interactive Multimodal Trajectory Prediction for Autonomous Driving**|Ziyi Huang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09366v1-b31b1b.svg)](http://arxiv.org/abs/2503.09366v1)|null|
|**2025-03-12**|**Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latant Space**|Jian Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09215v1-b31b1b.svg)](http://arxiv.org/abs/2503.09215v1)|null|
|**2025-03-11**|**Task-Oriented Co-Design of Communication, Computing, and Control for Edge-Enabled Industrial Cyber-Physical Systems**|Yufeng Diao et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08661v1-b31b1b.svg)](http://arxiv.org/abs/2503.08661v1)|null|
|**2025-03-11**|**HiP-AD: Hierarchical and Multi-Granularity Planning with Deformable Attention for Autonomous Driving in a Single Decoder**|Yingqi Tang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08612v1-b31b1b.svg)](http://arxiv.org/abs/2503.08612v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/nullmax-vision/hip-ad)**|
|**2025-03-11**|**V-Max: Making RL practical for Autonomous Driving**|Valentin Charraut et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08388v1-b31b1b.svg)](http://arxiv.org/abs/2503.08388v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/valeoai/v-max)**|
|**2025-03-11**|**Talk2PC: Enhancing 3D Visual Grounding through LiDAR and Radar Point Clouds Fusion for Autonomous Driving**|Runwei Guan et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08336v1-b31b1b.svg)](http://arxiv.org/abs/2503.08336v1)|null|

## Autonomous_Driving_LLM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-12**|**SimLingo: Vision-Only Closed-Loop Autonomous Driving with Language-Action Alignment**|Katrin Renz et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09594v1-b31b1b.svg)](http://arxiv.org/abs/2503.09594v1)|null|
|**2025-03-11**|**CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving**|Changxing Liu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08683v1-b31b1b.svg)](http://arxiv.org/abs/2503.08683v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/cxliu0314/colmdriver)**|
|**2025-03-11**|**FASIONAD++ : Integrating High-Level Instruction and Information Bottleneck in FAt-Slow fusION Systems for Enhanced Safety in Autonomous Driving with Adaptive Feedback**|Kangan Qian et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08162v1-b31b1b.svg)](http://arxiv.org/abs/2503.08162v1)|null|

## Autonomous_Driving_RL

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-13**|**Finetuning Generative Trajectory Model with Reinforcement Learning from Human Feedback**|Derun Li et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10434v1-b31b1b.svg)](http://arxiv.org/abs/2503.10434v1)|null|
|**2025-03-12**|**Edge AI-Powered Real-Time Decision-Making for Autonomous Vehicles in Adverse Weather Conditions**|Milad Rahmati et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09638v1-b31b1b.svg)](http://arxiv.org/abs/2503.09638v1)|null|
|**2025-03-11**|**V-Max: Making RL practical for Autonomous Driving**|Valentin Charraut et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08388v1-b31b1b.svg)](http://arxiv.org/abs/2503.08388v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/valeoai/v-max)**|
|**2025-03-10**|**AlphaDrive: Unleashing the Power of VLMs in Autonomous Driving via Reinforcement Learning and Reasoning**|Bo Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.07608v1-b31b1b.svg)](http://arxiv.org/abs/2503.07608v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/hustvl/alphadrive)**|

## World_Model

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-03-14**|**A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving**|Tin Stribor Sohn et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11400v1-b31b1b.svg)](http://arxiv.org/abs/2503.11400v1)|null|
|**2025-03-14**|**DriveGEN: Generalized and Robust 3D Detection in Driving via Controllable Text-to-Image Diffusion Generation**|Hongbin Lin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11122v1-b31b1b.svg)](http://arxiv.org/abs/2503.11122v1)|null|
|**2025-03-14**|**Active Learning from Scene Embeddings for End-to-End Autonomous Driving**|Wenhao Jiang et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.11062v1-b31b1b.svg)](http://arxiv.org/abs/2503.11062v1)|null|
|**2025-03-13**|**TAIJI: Textual Anchoring for Immunizing Jailbreak Images in Vision Language Models**|Xiangyu Yin et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10872v1-b31b1b.svg)](http://arxiv.org/abs/2503.10872v1)|null|
|**2025-03-13**|**OCCUQ: Exploring Efficient Uncertainty Quantification for 3D Occupancy Prediction**|Severin Heidrich et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.10605v1-b31b1b.svg)](http://arxiv.org/abs/2503.10605v1)|**[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ika-rwth-aachen/occuq)**|
|**2025-03-12**|**Evaluating the Impact of Synthetic Data on Object Detection Tasks in Autonomous Driving**|Enes Özeren et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09803v1-b31b1b.svg)](http://arxiv.org/abs/2503.09803v1)|null|
|**2025-03-12**|**Edge AI-Powered Real-Time Decision-Making for Autonomous Vehicles in Adverse Weather Conditions**|Milad Rahmati et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09638v1-b31b1b.svg)](http://arxiv.org/abs/2503.09638v1)|null|
|**2025-03-12**|**A Case Study on Model Checking and Runtime Verification for Awkernel**|Akira Hasegawa et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09282v1-b31b1b.svg)](http://arxiv.org/abs/2503.09282v1)|null|
|**2025-03-12**|**Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latant Space**|Jian Zhu et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.09215v1-b31b1b.svg)](http://arxiv.org/abs/2503.09215v1)|null|
|**2025-03-13**|**JiSAM: Alleviate Labeling Burden and Corner Case Problems in Autonomous Driving via Minimal Real-World Data**|Runjian Chen et.al.|[![arxiv](https://img.shields.io/badge/arXiv-2503.08422v2-b31b1b.svg)](http://arxiv.org/abs/2503.08422v2)|null|

